\documentclass{report}

\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage{xstring}
\usepackage{tikz}
\usepackage{amsthm}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage[a4paper, top = 2cm, left = 2.5cm, right = 2.5cm, bottom = 2cm]{geometry}
\title{Lineare Algebra I\\Mitschrieb}



\titleformat{\chapter}[block]
{\normalfont\huge\bfseries}{}{0em}{\Huge}
\titlespacing*{\chapter}{-7pt}{-15pt}{20pt}
\titlespacing*{\section}{-7pt}{0pt}{10pt}
\titlespacing*{\subsection}{-7pt}{0pt}{10pt}


% ease of use commands
\newcommand{\lb}{\lambda}
\newcommand{\mlb}{$\lb$}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\mR}{$\mathbb{R}$\ }
\newcommand{\mN}{$\mathbb{N}$\ }
\newcommand{\mZ}{$\mathbb{Z}$\ }
\newcommand{\mQ}{$\mathbb{Q}$\ }
\newcommand{\mC}{$\mathbb{C}$\ }
\newcommand{\Rn}{\mathbb{R}^n\ }
\newcommand{\mRn}{$\mathbb{R}^n$\ }
\newcommand{\al}{\alpha}
\newcommand{\be}{\beta}
\newcommand{\vtwo}[2]{\begin{pmatrix}#1 \\ #2 \end{pmatrix}}
\newcommand{\vthree}[3]{\begin{pmatrix}#1 \\ #2 \\ #3 \end{pmatrix}}
\newcommand{\ve}[1]{{\begin{pmatrix}#1 \end{pmatrix}}}
\renewcommand{\v}{\ve}
\DeclareMathOperator{\abb}{Abb}

% increase line height
\renewcommand{\baselinestretch}{1.2}

% define environments
\newtheoremstyle{customdef} % name of the style to be used
	{12pt}  % measure of space to leave above the theorem. E.g.: 3pt
	{12pt}  % measure of space to leave below the theorem. E.g.: 3pt
	{\normalfont} % name of font to use in the body of the theorem
	{-7pt}      % measure of space to indent
	{\bfseries}% name of head font
	{ \\[.125cm] }     % punctuation between head and body
	{ }        % space after theorem head; " " = normal interword space
	{\thmname{#1}\thmnumber{ #2} {\normalfont\thmnote{ -- \hspace{1pt}  #3}}}

\newtheoremstyle{customrem} % name of the style to be used
	{-7pt}  % measure of space to leave above the theorem. E.g.: 3pt
	{0pt}  % measure of space to leave below the theorem. E.g.: 3pt
	{}     % name of font to use in the body of the theorem
	{}     % measure of space to indent
	{\itshape}% name of head font
	{:}       % punctuation between head and body
	{.5em} % space after theorem head; " " = normal interword space
	{}
\theoremstyle{customrem}
\newtheorem*{bem}{Bemerkung}
\theoremstyle{customdef}
\newtheorem{definition}{Definition}[chapter]
\newtheorem*{definition*}{Definition} % without numbering
\newtheorem{prop}[definition]{Proposition}
\newtheorem{lem}[definition]{Lemma}
\newtheorem{kor}[definition]{Korollar}
\newtheorem{satz}[definition]{Satz}
\newtheorem*{satz*}{Satz} % without numbering
\renewenvironment{proof}{\vspace{-.75cm}\paragraph{Beweis: }}{\vspace{-.5cm}\hfill$\square$}
%\renewcommand{\qedsymbol}{$\square$}
% replace ugly hyperref boxes with colored text
\usepackage{xcolor}
\hypersetup{
	colorlinks,
	linkcolor = {red!50!black},
	urlcolor  = {blue!80!black}
}
\setcounter{chapter}{-1}

\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
	\hskip -\arraycolsep
	\let\@ifnextchar\new@ifnextchar
	\array{#1}}
\makeatother

\begin{document}
\begin{titlepage}
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
	\center
	\vspace{6cm}
	\textsc{\large Albert-Ludwigs-Universität Freiburg}\\[0.5cm] 
	\vspace{4cm}
	\HRule \\[0.8cm]
	{ \huge \bfseries Lineare Algebra $\mathbf{I}$}\\[0.4cm] 
	\HRule \\[.5cm]
	\Large Inoffizieller Mitschrieb
	\\[13.5cm]
	\begin{minipage}{0.5\textwidth}
		\begin{center} \large
			\emph{Vorlesung gehalten von:}\\[1cm]
			Prof. Dr. Patrick Dondl\\
			Abteilung für Angewandte Mathematik\\
		\end{center}
	\end{minipage}\\[2.5cm]
	\thispagestyle{empty}
\end{titlepage}


\section*{Einführung}
\begin{itemize}
\item{Das Wort Algebra stammt aus dem arabischen "`al-jabr"'.}
\item{Allgemein ist Algebra die Lehre der mathematischen Symbole und deren Manipulation.}
\item{Lineare Algebra: Insbesondere lineare Gleichungen}
\end{itemize}

\subsection*{Aufbau der Vorlesung}
\begin{enumerate}
\item{Lineare Gleichungssysteme und der n-dimensionale reellen Raum}
\item{Grundlegende Objekte}
\item{Gruppen, Ringe, Körper}
\item{Vektorräume und lineare Abbildungen}
\item{Determinanten}
\item{Eigenwerte und Normalformen}
\end{enumerate}

\subsection*{Beispiel: Der Google Pagerank}
Gegeben seien vier Seiten mit Verlinkungen zwischen diesen Seiten. Von einer nicht verlinkten Seite wechselt man zufällig auf eine andere Seite. Der User startet an einer zufälligen Stelle und folgt von dort einem zufälligen Link auf eine andere Seite. Zusätzlich wird immer mit Wahrscheinlichkeit $(1-d), \ d \in [0, 1]$ auf eine beliebige Website gewechselt.\\
Die wichtigste Seote ist nun die, auf welcher ein Benutzer sich mit der höchsten Wahrscheinlichkeit aufhält.\\
$$
p(\delta_1) = \frac{1-d}{N} + d\left(\frac{p(\delta_2)}{1}, \frac{p(\delta_5)}{4}\right)$$$$
p(\delta_2) = \frac{1-d}{N} + d\left(\frac{p(\delta_1)}{3}, \frac{p(\delta_5)}{4}\right)$$$$
\vdots
$$\\
Zur Berechnung von $p(\delta_j), j \in \{1..5\}$ gibt es Methoden aus der linearen Algebra.
\newpage
\tableofcontents
\newpage

\chapter{Lineare Gleichungssysteme und der \\ $\mathbf{n}$-dimensionale reelle Raum}

\begin{itemize}
	\item Descartes führte ``Koordinaten'' ein in der Geometrie ein, also Zahlensysteme. Das führte dazu, das man nun leichter rechnen kann.
	\item Wir benutzen hier die reellen Zahlen (mit den üblichen Rechenregeln für die Addition):
		\begin{itemize}
			\item $(x + y) + z = x + (y + z)$ \\
			\item $0 + x = x + 0 = x$ 
			\item Es gibt für jedes x ein y mit $x + y = 0$, wir nennen dieses y das additiv inverse zu x (``-x'').
			\item $x + y = y + x$
		\end{itemize}
		Und für Multiplikation:
		\begin{itemize}
			\item $\lambda (x + y) = \lambda x + \lambda y$ 
			\item $(\lambda + \mu) x = \lambda x + \mu x)$
			\item $\lb(\rho\mu)=(\lb\rho)\mu$
			\item $1x = x$
		\end{itemize}
	\item Weiterhin brauchen wir die natürlichen Zahlen, die $1,2,3\dots$
\end{itemize}

\section{Der $\R^n$}
	Für gegebenes $n \in \N$ definieren wir:\\
	$$\R^n = \{x = (x_1, x_2, \dots, x_n): x_1, \dots, x_n \in \R\}$$
	Hierbei ist $(x_1, \dots, x_n)$ ein geordnetes $n$-Tupel, die Reihenfolge beim Vergleich Elemente dieser Art ist wichtig.\\
	Weiterhin gilt: $x, y, \in \R : x = y \Leftrightarrow x_1 = y_1, x_2 = y_2,\ \dots \ x_n, = y_n$\\
	Wir nennen diese $n$-Tupel auch Vektoren im \mRn.\\
	Mit $\R^0$ bezeichnen wir die Menge $\{0\}$, welche nur das Nullelement enthält. Allgemein übertragen sich die Rechenregeln von \mR. Wir schreiben:
	\begin{align*}
		x + y =& (x_1 + y_1, \dots, x_n + y_n)\text{ für } x, y \in \Rn\qquad \tag*{Vektoraddition}\\
		\lb x = &(\lb x_1, \dots, \lb x_n)\qquad \tag*{Skalarmultiplikation}
	\end{align*}
	
	\begin{definition*}[Lineare Gleichungssysteme]
		Eine lineare Gleichung über \mR ist ein Ausdruck der Form: $\alpha_1x_1 + \alpha_2 x_2 + \dots \alpha_n x_n = \beta$ für reelle Zahlen $\beta, \alpha_1, \dots, \alpha_n \in \R$. Einen Vektor, $\xi = \left(\xi_1, \dots, \xi_n\right) \in \Rn$ nennen wir Lösung, wenn die reellen Zahlen  $\xi_1, \ \dots\ , \xi_n$ eingesetzt in $x_1, \dots, x_n$ die Gleichung erfüllen.\\
		Ein lineares Gleichungssystem G ist ein System der Form
		
		\begin{alignat*}{4}
			a_{11} x_1 &+ a_{12}x_2 &+\ \dots\ +\ & a_{1n} x_n &= b_1\\
			a_{21} x_1 &+ a_{22}x_2 &+\ \dots\ +\ & a_{2n} x_n &= b_2\\
			\vdots\quad & \qquad\vdots&\ddots\quad \ \ &\quad\vdots & \vdots\  \\
			a_{m1} x_1 &+ a_{m2} x_2  &+\ \dots\ +\ & a_{mn} x_n &= b_m\\
		\end{alignat*}
		
		Die einzelnen Komponenten lassen sich auch zusammenfassen als $$\sum_{j=1}^n a_{i,j} x_j = b_i \quad i\in\{1,\dots,m\}$$
		oder, noch kürzer, in Matrixschreibweise:
			$$Ax=b$$\\
		Dabei bezeichnet $A$ eine sog. Matrix mit den Einträgen $a_{i,j},\ i\in[0,\ \dots\ , m],\ j\in[0,\ \dots\ , n]$, wir schreiben\\
		$$A =
		\begin{pmatrix}
			a_{11} & \dots  & a_{1n}\\
			\vdots & \ddots & \vdots\\
			a_{m1} & \dots  & a_{mn}
		\end{pmatrix}
		$$\\
		$Ax$ für $x \in \Rn$ ist dann eine Kurzform für $\sum_{i=1}^na_{ij}x_j$ mit einem Vektor $x = (x_1, \dots, x_n) \in \Rn$. Das Ergebnis ist ein Vektor $b = (b_1, \dots, b_m) \in \R^m$ für eine Matrix $A$ mit $m$ Zeilen und $n$ Spalten.\\
		Der Vektor $b$ heißt rechte Seite des linearen Gleichungssystems, $A$ heißt Koeffizientenmatrix des linearen Gleichungssystems. Eine Spalte, bzw. Zeile von $A$ kann mit einem Vektor im $\R^m$ bzw. im $\R^n$ identifiziert werden. Wir sprechen von Spalten-, bzw. Zeilenvektoren der Matrix $A$.\\
		Eine Matrix mit $m$ Zeilen und $n$ Spalten nennen wir $m\times n$ - Matrix. Für $x  \in \Rn $, $A$ eine $m\times n$ - Matrix und $B$ eine $l\times m$ - Matrix gilt die Rechenregel $BAx = B(Ax)$. Ein Gleichungssystem $Ax=b$ heißt homogen, falls $b$ der Nullvektor $(0, \dots, 0)$ ist und quadratisch für  $m = n$ (eine quadratische Matrix A).\\
	\end{definition*}
	
	\begin{definition*}[Normalform]
	
		Ein Gleichungssystem $Ax=b$ ist in Normalform, falls $A$ die Gestalt \\
		$$\hspace{3cm}
		\left(
		\begin{matrix}
			\text{\scriptsize $k$}\left\{\vphantom{
				\begin{matrix}
				1 & 0 & 0 & \ \cdots \ & 0\\
				0 & 1 & 0 & \ \cdots \ & 0\\
				0 & 0 & 1 & \ \cdots \ & 0 \\
				\vdots & \vdots & \vdots&\ddots & \vdots\\
				0 & 0 & 0 & \ \cdots \ & 1\\
				\end{matrix}}\right.\kern-2\nulldelimiterspace
			\underbrace{
			\begin{matrix}
				1 & 0 & 0 & \ \cdots \ & 0\\
				0 & 1 & 0 & \ \cdots \ & 0\\
				0 & 0 & 1 & \ \cdots \ & 0 \\
				\vdots & \vdots & \vdots&\ddots & \vdots\\
				0 & 0 & 0 & \ \cdots \ & 1\\
			\end{matrix}}_{k}
			&
			\begin{matrix}
				a_{1, k+1} & \ \cdots \ & a_{1, n}\\
				a_{2, k+1} & \ \cdots \ & a_{2, n}\\
				a_{3, k+1} & \ \cdots \ & a_{3, n}\\
				\cdots & \ \ddots \ & \vdots\\
				a_{k, k+1} & \ \cdots \ & a_{k, n}\\
			\end{matrix} \\
			\hspace{.5cm}
			\begin{matrix}
				0 &\hspace{.25cm}  & \cdots & \hspace{.25cm}& 0\\
				\vdots &  & \ddots & &\vdots\\
				0 &  & \cdots & & 0\\
			\end{matrix}
			&
			\begin{matrix}
				0 &\hspace{.25cm}\ \cdots\ \hspace{.25cm}& 0\\
				\vdots &\ \ddots\ & \vdots\\
				0 &\ \cdots\ & 0\\
			\end{matrix}
		\end{matrix}
		\hspace{.15cm}
		\right)\text{\hspace{1cm}für ein $k \in \N_0$}$$
		annimmt. Beispiele:\\
		$$
		\begin{pmatrix}
			1 & 0 & 3\\
			0 & 1 & 4\\
			0 & 0 & 0\\
			0 & 0 & 0\\
		\end{pmatrix}\text{\hspace{.75cm}Ist in Normalform mit $k = 2$.}
		$$
		$$
		\begin{pmatrix}
			1 & 0 & 0\\
			0 & 1 & 0\\
			0 & 0 & 1\\
		\end{pmatrix}\text{\hspace{.75cm}Ist in Normalform mit $k = 3$.}
		$$
		$$
		\begin{pmatrix}
			0 & 0\\
			0 & 0\\
		\end{pmatrix}\text{\hspace{.75cm} Ist in Normalform mit $k = 0$.}
		$$
		Wir nennen $k$ den Rang der Matrix $A$ (bzw. des Gleichungssystems). Es gilt $0 \le k \le \min(m, n) $.
		Ein Gleichungssystem ist genau dann lösbar,  wenn gilt: $b_{k+1} = b_{k+2} = \ldots = b_m = 0$. 
		In diesem Fall lässt sich eine Lösung $\xi \in \Rn$ bestimmen,  indem man $\xi_{k+1}, \dots, \xi_n$ beliebig wählt, und danach $\xi_i = b_i -  \sum_{j=k+1}^n a_{i,j} \xi_j, \ i\in\{1,\dots,n\}$ wählt. Wir sagen die Lösungsmenge ist \\
		$$\mathbb{L} =\left\{\left(b_1 - \sum_{j=k+1}^na_{1j}\xi_j\right), \dots,  \left(b_k - \sum_{j=k+1}^{n}a_{kj}\xi_j\right), \xi_{k+1}, \dots, \xi_n \Big| \xi_{k+1}, \dots, \xi_n \in \R\right\}$$
		Wir nennen eine solche Menge $(n-k)$-parametrig.\\
	
		%Denn für Zeile $i, i=k+1, \dots, n$ lautet das Gleichungssystem $0x_1 + \dots + 0x_n = b_i = 0$ und \\
		%Für Zeile $i, i =1, \dots, k$ 
		%$$a_{i, i} x_i + \sum_{j=k+1}^n a_{i,j} x_j = b_i$$
		\noindent Beispiel:
		$$
		\begin{pmatrix}
			1 & 0 & 3\\
			0 & 1 & 4\\
			0 & 0 & 0\\
			0 & 0 & 0\\
		\end{pmatrix} x =
		\begin{pmatrix}
			1\\1\\0\\0
		\end{pmatrix}
		$$
		Wähle $x_3 = 1$. Dann folgt daraus $x_2 = -3$ und $x_1 = -2$.
	\end{definition*}
	
	\begin{lem}
		Sei A eine $m\times n$ -Matrix mit Rang $k$. Dann gilt $k=n$  genau dann, wenn alle Gleichungssysteme mit $A$ höchstens eine Lösung haben, und $k = m$, genau dann, wenn alle Gleichungssysteme mit $A$ lösbar sind.\\
		Beweis: klar aus der Darstellung.
	\end{lem}
	
	\begin{definition*}[Zeilenoperationen]
		Eine Zeilenoperation macht aus einem Gleichungssystem ein neues Gleichungssystem durch Multiplikation  der $i$-ten Zeile mit einer Zahl $\lb \in \R \setminus 0$ oder durch Addieren des \mlb-fachen der $i$-ten Zeile zur $j$-ten Zeile $(i \neq j)$. Wir bezeichnen diese Operationen mit $Z_i^\lb$ bzw. $Z_{i,j}^\lb$.\\
		Die Umkehrung von $Z_i^\lb = Z_i^{\frac{1}{\lb}}$, die Umkehrung von $Z_{i,j}^\lb = Z_{i,j}^{-\lb}$
		\begin{bem}
			Die Zeilenoperationen sind umkehrbar.
		\end{bem}
	\end{definition*}
		
	\begin{lem}
		Ein Gleichungssystem $G'$, welches aus einem Gleichungssystem $G$ durch Zeilenoperationen hervorgeht, besitzt die gleichen Lösungen wie $G$.\\
		Beweis:\\
		Für $Z_I^\lb: $ betrachten wir nur die $i$-te Zeile:
		$$a_{i,1}x_1 + \dots + a_{i,n}x_n = b_i$$
		Nach $Z_i^\lb$:
		$$\lb a_{i,1}x_1 + \dots + \lb a_{i,n}x_n = \lb b_i$$
		Diese besitzen eindeutig die selbe Lösungen $\xi_1, \dots, \xi_n$, ebenso für $Z_{i,j}^\lb$.
	\end{lem}
	
	\begin{satz}[Gauß-Jordan-Elimination]
		Jedes lineare Gleichungssystem lässt sich durch Zeilenoperationen und Vertauschungen von Variablen (d.h. Vertauschung von Spalten) in Normalform bringen.\\[.5cm]
		\begin{proof}
			Wir beweisen dies mittels eines expliziten  Algorithmus' (der Gauß-Jordan-Elimination).	Aus praktischen Gründen schreiben wir unser Gleichungssystem als sogenannte erweiterte Koeffizientenmatrix.
			$$
			\begin{pmatrix}[cccc|c]
				a_11   & a_12   & \cdots & a_1n   & b_1\\
				\vdots & \vdots & \ddots & \vdots & \vdots\\
				a_m1   & a_m2   & \cdots & a_mn   & b_m\\
			\end{pmatrix}
			$$
			Zunächst vergewissern wir uns, dass wir durch vermehrte Anwendung von $Z_{i,j}^1, Z_{j,i}^{-1}, Z_{i,j}^1$und $ Z_{i}^{-1}$ die $i$-te und $j$-te Zeile vertauschen können.\\
			Sei $y$ die $i$-te Zeile, $z$ die $j$-te Zeile.
			$$
			\vtwo{y}{z} \overset{Z_{i,j}^1}{\longrightarrow}  \vtwo{y}{z+y} \overset{Z_{j, i}^{-1}}{\longrightarrow}  \vtwo{-z}{z+y} \overset{Z_{i,j}^1}{\longrightarrow}  \vtwo{-z}{y} \overset{Z_{i}^{-1}}{\longrightarrow} \vtwo{z}{y}
			$$
			\textbf{Schritt 1}:\ Falls alle Koeffizienten $a_{i,j}=0$ sind, so ist die Matrix bereits in Normalform, und es ist nichts mehr zu tun.\\
			Falls es einen von $0$ verschiedenen Koeffizienten gibt, so können wir diesen durch Spalten- und Zeilenvertauschungen in die linke obere Ecke bringen. Damit ist nun $a_{1,1} \neq 0$. Nach $Z_{1}^{\frac{1}{a_{1,1}}}$ gilt $a_{1,1} = 1$. Nun wenden wir $Z_{1,2}^{-a_{2,1}}, \dots, Z_{1,m}^{-a_{m,1}}$ und erhalten $a_{2,1} = \dots = a_{m,1} = 0$.
			Die Matrix hat nun die Form $$
			\begin{pmatrix}[cccc|c]
			1 & a_{1, 2} & \dots   & a_{1, n}   & b_1\\
			0 & \ddots 	 &		   &			& \\
			0 & 		 & \ddots\ &			& \vdots\\
			\vdots&		 &		   & \ddots\	&\\
			0 & a_{m, 2} & \dots   & a_{m, n}   & b_m
			\end{pmatrix}
			$$\\
			\textbf{Schritt 2}:\ Falls $a_{i,j} = 0$ für $2 \le i \le m$ und $2 \le j \le n$, so ist die Matrix in Normalform für k=1 und wir sind fertig. Falls nicht, so existiert $i \ge 2, j\ge 2$ mit $a_{i,j} \neq 0$.\\
			Wir vertauschen die $i$-te Zeile mit der zweiten Zeile, und die $j$-te Spalte mit der zweiten Spalte. Damit ist $a_{2,2} \neq 0$. Nun wenden wir $Z_{2}^{\frac{1}{a_{2,2}}}$ an. Damit ist $a_{2,2} = 1$. Jetzt wenden wir $Z_{2,1}^{-a_{1,2}}, \dots, Z_{2,m}^{-a_{m,2}}$ an und erhalten die Form:
			$$
			\begin{pmatrix}[ccccc|c]
			1 & 0 & a_{1, 3} & \dots & a_{1, n} & b_1\\
			0 & 1 & a_{2, 3} & \dots & a_{1, n} & b_2\\
			0 & 0 & \ddots	 &		 & 			& b_3\\
			\vdots&&		 & \ddots&			& \vdots\\
			0 & 0 & a_{m, 3} & \dots & a_{m, n} & b_m
			\end{pmatrix}
			$$\\
			Wir verwandeln damit der Reihe nach die Spalten der Matrix in Spalten, in welchen nur der Diagonaleintrag von $0$ verschieden ist (dieser Eintrag ist gleich 1).
			Das Verfahren terminiert, wenn die Matrix in Normalform ist, oder wenn $\min(n, m)$ Schritte vollzogen sind. Auch in diesem Fall ist die Matrix in Normalform.
		\end{proof}
	\end{satz}
	
	\begin{kor}
		Sei $A$ eine Matrix mit $m$ Zeilen und $n$ Spalten. Weiter sei $k$ der Rang einer Normalform von $A$ (d.h. einer Matrix in Normalform, welche aus $A$ durch Zeilenoperationen und Spaltenvertauschungen hervorgeht). Ein Gleichungssystem  mit Matrix $A$ besitzt dann entweder keine Lösung, oder ein $(n-k)$-parametriges Lösungssystem. Es gilt $k=n$ genau dann, wenn jedes Gleichungssystem $Ax=b$ höchstens eine Lösung besitzt und $k=m$ genau dann, wenn jedes Gleichungssystem $Ax=b$ mindestens eine Lösung besitzt.\\
		\begin{proof}
			Folgt aus Lemma 0.2 und daraus, dass Zeilen-, bzw. Spaltenoperationen die Lösungsmenge (modulo Variablentausch) nicht ändern.
		\end{proof}
	\end{kor}
	
	\begin{kor}
		\label{kor5}
		Ein homogenes Gleichungssystem mit weniger Gleichungen als Variablen hat mindestens eine nicht triviale Lösung.\\
		\begin{proof}
			Es gibt für homogene Gleichungssysteme immer die triviale Lösung. Der Rang der Matrix des Gleichungssystems in Normalform sei k. Damit existiert ein $(n-k)$-parametriges Lösungssystem, aber $k \le min(n, m) \le m \le (n-1)$. Somit existiert mindestens eine weitere Lösung.
		\end{proof}
	\end{kor}

	\begin{definition}[Lineare Unabhängigkeit]
		Eine Kollektion $a_1, \dots, a_n$ von Vektoren in $\R^m$ heißt linear unabhängig, wenn sich keiner der Vektoren als Linearkombination der anderen Vektoren schreiben lässt.
	\end{definition}
	
	\begin{bem}
		Als Linearkombination von $a_1, \dots, a_n$ bezeichnen  wir einen Ausdruck der Form $\al_1a_1 + \al_2 a_2 + \ldots + \al_n a_n = \sum_{j=1}^n \al_j a_j$ für $\al_1, \dots, \al_n \in \R$
	\end{bem}

	\begin{lem}
		\label{lem10}
		Vektoren $a_1, \dots, a_n$ sind genau dann linear unabhängig, wenn für alle $\xi_1, \dots, \xi_n \in\R$ gilt: Falls $\xi_1a_1 + \dots + \xi_na_n = 0$, dann gilt $\xi_1 = \dots = \xi_n = 0$.\\
		\begin{proof}
			\begin{enumerate}
				\itemsep-.125cm
				\item Falls $0 = \xi_1 a_1 + \dots + \xi_n a_n$, und oBdA $\xi_1 \neq 0$ so folgt $a_1 = \sum_{j=2}^n -\frac{\xi_j}{\xi_1} a_j$. Somit wurde $a_1$ als Linearkombination von $a_2, \dots, a_n$ geschrieben.
				\item Falls aber oBdA $a_1 = \sum_{j=2}^n \lb_j a_j$ so gilt: $0 = -a_1 = \sum{j=2}^n$, damit ist $\xi_1$ (der erste Koeffizient) von $0$ verschieden.
			\end{enumerate}
		\end{proof}
	\end{lem}
	
	\begin{lem}
		\label{lem11}
		Es seien $a_1, \dots, a_n \in \R^m$  linear unabhängig und es gelte $b = \lb_1a_1 + \dots + \lb_n a_n$, mit $\lb_1, \dots, \lb_n \in \R$. Dann ist diese Linearkombination eindeutig.\\
		\textbf{Beweis:} Es sei auch $b = \mu_1 a_1 + \dots + \mu_n a_n$. Für Eindeutigkeit ist nun zu zeigen, dass $\mu_i = \lb_i, 1 \le i \le n$.
		Wir ziehen die Gleichungen voneinander ab, und erhalten:
		$$
		b - b= (\lb_1 - \mu_1) a_1 + \ldots + (\lb_n - \mu_n) a_n$$$$
		\Leftrightarrow \ 0 = (\lb_1 - \mu_1) a_1 + \ldots + (\lb_n - \mu_n) a_n
		$$
		Mit \hyperref[lem10]{Lemma \ref{lem10}} folgt die Aussage.
	\end{lem}
	
	\begin{satz}
		\label{satz12}
		Wenn man ein Gleichungssystem durch Zeilenoperationen und Spaltenvertauschungen auf Normalform bringt, so erhält man immer denselben Rang.		
		\begin{bem}
			Man kann damit vom Rang eines Gleichungssystems (bzw. einer Matrix) sprechen, auch wenn dieses nicht in Normalform ist.
		\end{bem}
		\begin{bem}
			Ein einzelner Vektor $a$ gilt als linear unabhängig, solange $a \neq 0$. Die leere Kollektion von Vektoren $(n=0)$ bezeichnen wir ebenfalls als linear unabhängig.
		\end{bem}
		\noindent Vor dem Beweis des \hyperref[satz12]{Satzes \ref{satz12}} noch ein paar Feststellungen:
		\begin{enumerate}
			\item Die Tatsache, dass $(\xi_1, \dots, \xi_n)$ Lösung eines linearen Gleichungssystems ist, lässt sich als lineare Abhängigkeit 
			$\xi_1a_1 + \dots + \xi_n a_n = b$ ausdrücken, wobei $a_i$ eine Spalte der Matrix des Gleichungssystems ist.
			\item Ist das Gleichungssystem in Normalform, so sind die ersten k Spaltenvektoren linear unabhängig. Die folgenden $n-k$ Spaltenvektoren lassen sich aber als Linearkombination der ersten $k$ darstellen, also
			$$
			\lb_{1,i}a_1 + \dots + \lb_{k,i}a_k = a_i \text{ für } k < i \le n
			 \text{ mit }  \lb_{1,i} = a_{1,i}, \dots
			$$
			\item Falls das Gleichungssystem lösbar ist, kann man dank $\xi_1a_1 + \dots + \xi_n a_n = b$ auch $b$ als solche Linearkombination schreiben. Wegen \hyperref[lem11]{Lemma \ref{lem11}} sind diese Linearkombinationen auch eindeutig.
		\end{enumerate}
		\begin{proof}
			Wir bemerken zunächst, dass Zeilenoperationen und Spaltenvertauschung die Anzahl linear unabhängiger Spaltenvektoren nicht ändern.
			Wir überlegen uns nun, dass der Rang eines linearen Gleichungssystems nichts anderes als die maximale Anzahl linear unabhängiger Spaltenvektoren der Matrix ist.\\
			Die ersten k Spalten sind linear unabhängig, da die Matrix in Normalform ist. Seien also $a_{i_1}, \dots, a_{i_{k+1}}$ beliebige Spaltenvektoren der Matrix des Gleichungssystems. Nachdem in diesen Vektoren alle Einträge ab dem $k+1$-ten Eintrag $0$ sind, hat das Gleichungssystem \\
			$$
			x_1a_{i_1} + \dots + x_{k+1}a_{i_{k+1}} = 0
			$$
			nur $k$ mögliche Gleichungen. (Die Zeilen $k+1$ bis $m$ in diesem Gleichungssystem sind $0=0$)\\
			Nach \hyperref[kor5]{Korollar \ref{kor5}} hat dieses homogene Gleichungssystem mit $k$ Gleichungen und $k+1$ Unbekannten aber mindestens eine nicht triviale Lösung. Die Vektoren $a_{i_1}, \dots a_{i_{k+1}}$ sind somit nicht linear unabhängig.
		\end{proof}
	\end{satz}
	
	\begin{kor}
		Wird ein Gleichungssystem \textit{nur} durch Zeilenoperationen (also ohne Variablentausch) auf Normalform gebracht, so ist die Matrix, die man erhält, immer die gleiche. Falls das Gleichungssystem lösbar ist, so ist auch das erhaltene $b$ immer das gleiche.
	\end{kor}

\section{Ein wenig euklidische Geometrie}

\subsection{Geraden und Ebenen}

	\begin{definition}[Geraden]
		$ $\vspace{-.5cm}
		\begin{enumerate}
			\item Sei $v \not= 0$ ein Vektor in \mRn. Mit $\R v$ bezeichnen wir die Menge an Vektoren in \mRn der Form $\R v = \{\lb v : \lb \in \R\}$
			\item Sei $a \in \Rn, v \in \Rn, v \neq 0$. Als (affine) Gerade bezeichnen wir die Menge der Vektoren der Form $g = \{a + \lb v : \lb \in \R\} = a + \R v$
		\end{enumerate}
	\end{definition}
	
	\begin{bem}
		Der Richtungsraum $\R v$ einer Geraden $g$ ist durch diese eindeutig bestimmt als Menge der Differenzen $x - y$ aus Vektoren in $g$.
	\end{bem}
	
	\begin{lem}
		Zwei Geraden $a + \R v, b + \R w$ sind genau dann gleich, wenn gilt $\R v = \R w$ und $a - b \in \R v$.\\
		\begin{proof}
			Sei also  $x = a + \R v$, d.h. $x = a + \lb v$ für ein $\lb \in \R$. Nach Annahme gilt $\R v = \R w$. Damit existiert ein $\mu \in \R$ mit $\lb v = \mu w$ und somit $x = a + \mu w$. Weiterhin haben wir nach Annahme, dass $a-b \in \R v$, also existiert ein $\xi \in \R$ mit $a - b = \xi w$, also $x = a - (a - b) + \xi w + \mu w$ und somit $x = b + (\xi + \mu) w$.
			Es ist also $x \in b + \R w$.\\
			Die Umkehrung, also die Behauptung, dass sich ein Punkt $y \in b + \R w$ auch als Punkt in $a + \R v$ schreiben lässt, folgt analog.
		\end{proof}
	\end{lem}
	\begin{lem}
		Durch zwei verschiedene Punkte in \mRn geht genau eine Gerade.\\
		\textbf{Beweis: } Übung
	\end{lem}

	\begin{definition}[Parallelität]
		Zwei Geraden heißen parallel, wenn sie die gleichen Richtungsräume haben.
	\end{definition}

	\begin{definition}
		Eine (affine) Ebene ist eine Menge der Form $a + \R v + \R w$ für linear unabhängige Vektoren $v, w$.
		\begin{bem}
			Auch hier gilt, das der Raum $\R v + \R w$ eindeutig bestimmt ist als Menge aller Differenzen von Punkten in der Ebene.
		\end{bem}
	\end{definition}

	\begin{lem}
		Zwei nicht-parallele Geraden, die in einer Ebene liegen, schneiden sich.\\
		\begin{proof}
			Es sei $E = c + \R v_1 + \R v_2$ eine Ebene, $g_1 = a_1 + \R b_1$, $g_2 = a_2 + \R b_2$ zwei Geraden in E.\\
			Wir suchen $\xi_1,\ \xi_1$, so dass $a_1 + \xi_1 w_1 = a_2 + \xi_2 w_2$. Nun schreiben wir $a_i = c + \beta_{1,i} v_1 + \beta_{2,i} v_2$ und $w_i = \al_{1,i} v_1 + \al_{2,i} v_2$ für $i =1,2$.\\
			Das führt auf das Gleichungssystem\\
			$$
			\al_{1,1} \xi_1 - \al_{1,2} \xi_2 = - \beta_{1,1} + \beta_{1,2}$$$$
			\al_{2,1} \xi_1 - \al_{2,2} \xi_2 = - \beta_{2,1} + \beta_{2,2}
			$$\\
			Nachdem $g_1, g_2$ nicht parallel sind, sind $w_1, w_2$ linear unabhängig. Damit sind aber die Spaltenvektoren der Matrix $
			\begin{pmatrix}
				\al_{1,1} & -\al_{1,2}\\
				\al_{2,1} & -\al_{2,2}
			\end{pmatrix}
			$ ebenfalls linear unabhängig. Damit besitzt das Gleichungssystem eine Lösung (da $k = m$) nach \hyperref[satz12]{Satz \ref{satz12}}.
		\end{proof}
	\end{lem}
	
\subsection{Das Skalarprodukt}
	Im Folgenden seien $a = (a_1, \dots, a_n), b = (b_1, \dots, b_n)$ zwei Vektoren in \mRn.
	
	\begin{definition}[Skalarprodukt]
		Das Skalarprodukt von $a$ und $b$ ist definiert als $(a, b) = \sum_{j=1}^n a_j b_j$.
	\end{definition}
	
	\begin{lem}
		Das Skalarprodukt zweier Vektoren $a$ und $b$ in \mRn ist eine sogenannte symmetrische, positiv definite Bilinearform, das heißt:
		\begin{enumerate}
			\item $(a, b) = (b, a)$ (symmetrisch) 
			\item $(a + b, c) = (a, c) + (b, c)$ (linear) 
			\item $(\lb a, b) = \lb(a, b)$ (linear) 
			\item $(a, a) \ge 0$ (positiv definit) 
			\item $(a, a) = 0$ genau dann, wenn $a=0$ 
		\end{enumerate}
		für alle Vektoren $a, b, c \in \Rn$, alle $\lb \in \R$.\\
		\textbf{Bemerkung}: aus 1. und 2. folgt $(a, b+c = (a,b) + (a,c)$ und $(a, \lb b) = \lb (a, b)$\ (Bilinearität).\\
		\begin{proof}
			1., 2., 3. sind klar aus der Definition. 4. und 5. folgen daraus, dass $(a, a) = a_1^2, \ldots, a_n^2$.
		\end{proof}
	\end{lem}

	\begin{definition}[Norm]
		Die Norm (oder Länge) von a ist $\sqrt{(a, a)} = ||a||$.
	\end{definition}

	\begin{definition}[Winkel zwischen Vektoren]$ $\vspace{-.5cm}
		\begin{enumerate}
			\item Der Winkel $\al$ zwischen zwei Vektoren $a, b \neq 0$ ist definiert durch $0 \le \al \le \pi$ und $cos(\al) = \frac{|(a,b)|}{||a||\cdot ||b||}$.
			\item Zwei Vektoren $a, b \in \R^n$ heißen orthogonal, falls gilt $(a, b) = 0$.
		\end{enumerate}
	\end{definition}
	
	\begin{lem}[Cauchy-Schwarzsche Ungleichung]
		Es gilt $|(a, b)| \le ||a||\cdot||b||$.\\
		\begin{proof}
			Es gilt für jedes beliebiges $\lb \in \R$:
			$0 \le (a + \lb b, a + \lb b) = (a, a) + 2 (\lb a, b) + \lb^2 (b, b)$.	Für $\lb = -\frac{(a,b)}{(b, b)}$ ergibt sich $0 \le (a, a) - 2 \frac{(a, b)^2}{(b, b)} + \frac{(a, b)^2}{(b, b)}$.
			Für $b = 0$ ist die Aussage des Lemmas klar. Es folgt $(a,b)^2 \le (a, a)(b,b)$
		\end{proof} 
		\begin{bem}
			Falls a und b linear unabhängig sind so folgt $|(a,b)| < ||a||||b||$, denn dann ist $a + \lb b \neq 0$ (für jedes $\lb \in \R$) und die Ungleichung ist strikt (d.h. mit "`$<$"').
		\end{bem}
	\end{lem}
	
	\begin{lem}[Dreiecksungleichung]
		Es gilt $||a+b|| \le ||a|| + ||b||$.\\
		\begin{proof}
			$ ||a+b||^2 = (a+b, a+b)= ||a||^2 + 2(a,b) + ||b||^2 \le ||a||^2 + 2 ||a||||b|| + ||b||^2 = (||a|| + ||b||)^2$
		\end{proof}
		
	\end{lem}
	
	\begin{kor}[$||x-y||$ ist eine Metrik]
		Der \mRn mit dem Abstand $d(x, y) = ||x - y||$ ist ein sogenannter metrischer Raum. Das bedeutet folgendes:
		\begin{enumerate}
			\itemsep0cm
			\item $d(x, y) \ge 0$
			\item $d(x, y) = 0 \Leftrightarrow x = y$
			\item $d(x, y) = d(y, x)$
			\item $d(x, z) \le d(x,y) + d(y,z)$
		\end{enumerate}
		für alle $x, y, z \in \Rn$.	Wir nennen $d$ einen Abstand.
	\end{kor}
\chapter{Grundlegende Objekte}

\section{Elementare Aussagenlogik}
	Aussagen (in der Mathematik) sind sprachliche Gebilde, welche entweder wahr (w) oder falsch (f) sind.\\
	Darstellung mittels Wahrheitstabelle:\\
	Beispiele:
	\begin{center}
		\begin{tabular}{l | l}
			Aussage&\\\hline\hline
			A: es sind am 2.11.2017 mehr als fünf Personen im Hörsaal Rundbau & w\\\hline
			B: Der Dozent der LA in FR im WS 17/18 heißt Peter & f
		\end{tabular}
	\end{center}

	\begin{definition}[Logische Operatoren]
		A, B seien Aussagen.
		\begin{enumerate}
			\item "`$\neg A$"', oder "`nicht A"' ist die Negation von A
			\begin{center}
				\begin{tabular}{c | c}
					A & $\neg A$\\\hline\hline
					w & f\\
					f & w
				\end{tabular}
			\end{center}
			\item Junktoren:\\
				$A \lor B$, "`A oder B"' ist wahr, wenn mindestens eine der Aussagen A, B wahr ist.\\
				$A \land B$, "`A und \ B"' ist wahr, wenn beide Aussagen A, B wahr sind.
				\begin{center}
					\begin{tabular}{c | c | c | c}
						A & b & $A \lor B$ & $A\land B$\\
						\hline\hline
						w & w & w & w\\
						f & w & w & f\\
						w & f & w & f\\
						f & f & f & f
					\end{tabular}
				\end{center}
			\item Implikationen:\\
				$A \Rightarrow B$ ist wahr, wenn A die Aussage B impliziert.\\
				$A \Leftrightarrow B$  ist wahr, wenn A genau dann wahr ist, wenn B wahr ist.
				\begin{center}
					\begin{tabular}{c | c | c | c}
						A & B & $A \Rightarrow B$ & $A \Leftrightarrow B$\\
						\hline\hline
						w & w & w & w\\
						f & w & w & f\\
						w & f & f & f\\
						f & f & w & w
					\end{tabular}
				\end{center}
		\end{enumerate}
		\textbf{Beispiel:} Sei G ein lineares Gleichungssystem mit m Zeilen, n Spalten und Grad k. Dann gilt
		\begin{center}
			\begin{tabular}{l c l}
				$k = n$ & $\Rightarrow$ & Lösung immer eindeutig.\\
				$A$ & $\Rightarrow$ &  $B$\\
			\end{tabular}
		\end{center}
		Um die Aussage $A \Rightarrow B$ zu zeigen, können wir annehmen, das A wahr ist und müssen folgern, das B ebenfalls wahr ist.\\
		\begin{bem} De Morgansche Gesetze
			\begin{enumerate}
				\item\ $(\neg A \lor \neg B) = \neg (A \land B)$
				\item\ $(\neg A \land \neg B)$ = $\neg (A \lor B)$
			\end{enumerate}
		\end{bem}
	\end{definition}


\section{Mengen und Abbildungen}
	Problem: Der Begriff der Menge ist sehr schwer zu definieren (Vgl. Russelsche Antinomie).\
	Endliche Mengen kann man durch Auflistung aller Elemente angeben, z.B. $X = \{x_1, x_2, x_3\}$.\ $x_1, x_2, x_3$ heißen dann Elemente von X und wir schreiben $x_1 \in X$.\\
	Reihenfolge der Elemente und Mehrfachauflistung sind nicht relevant. Die Mächtigkeit einer Menge ist die Anzahl paarweise verschiedener Elemente. $\{1, 2, 2, 3\}$ beispielsweise hat Mächtigkeit $3$.
	Die leere Menge $\{\}$ oder $\emptyset$ enthält kein Element.

	\begin{definition}[Teilmengen]$ $\vspace{-.75cm}
		\begin{enumerate}
			\itemsep0cm
			\item Eine Menge Y heißt Teilmenge von X, wenn aus $x \in Y$ immer folgt $x \in X$. Wir schreiben $Y \subset X$.
			\item Wir sagen $X=Y$ genau dann, wenn $X \subset Y$ und $X \supset Y$\ d.h. zwei Mengen sind gleich, wenn sie die gleichen Elemente enthalten. ("`Extensionalitätsprinzip"')
		\end{enumerate}
		\begin{bem}$ $
			\begin{enumerate}
				\item $\emptyset \subset M$, für jede Menge M
				\item $M \subset M$, für jede Menge M
				\item Wenn gilt $M \subset N$, aber nicht $M = N$, dann heißt $M$ "`echte Teilmenge"' von $N$, wir schreiben dann $M \subsetneq N$. (Die ISO-Vorschrift sieht hier $\subset$ für "`echte Teilmenge"' und $\subseteq$ für "`Teilmenge"' vor, dies wird jedoch selten benutzt.)
			\end{enumerate}
		\end{bem}
		\textbf{Die Natürlichen Zahlen}\\
		Die einfachste unendliche Menge ist die der natürlichen Zahlen $$\N = \{1, 2, 3, \ldots\},$$ deren Existenz wir annehmen, zusammen mit den üblichen Rechenregeln.
		Die natürlichen Zahlen genügen dem Prinzip der vollständigen Induktion.
		Sei $M \subset \N$ und es gelte:
		\begin{enumerate}
			\itemsep0cm
			\item $1 \in M$
			\item falls $m \in M$, so ist auch $n + 1 \in M$
		\end{enumerate}
		Dann gilt $M = \N$.\\
		Durch Erweiterung von Zahlbereichen können wir aus \mN auch die ganzen Zahlen $\mathbb{Z}$, die rationalen Zahlen $\mathbb{Q}$ sowie die reellen Zahlen \mR konstruieren 
		(ebenso die komplexen Zahlen $\mathbb{C}$).\\
		\begin{bem}
			Es gilt $\N \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R} \subset \mathbb{C}$\\
		\end{bem}
		\noindent\textbf{Teilmengen mit Eigenschaften}\\
		Aus einer Menge können wir Teilmengen auswählen, welche durch bestimme Eigenschaften charakterisiert werden. Wir schreiben
		$$X' = \{x \in X : x \text{ hat Eigenschaft }E\}$$ oder auch $$X' = \{x \in X\ |\ x \text{ hat Eigenschaft E}\}.$$
	\end{definition}
	
	\begin{definition}[Mengenoperationen]
		\label{defmengenoperationen}
		Sind $X$, $Y$ Mengen, so können wir bilden:
		\begin{enumerate}
			\itemsep0cm
			\item Die Vereinigung $X \cup Y$, ist die Menge aller Elemente, welche in $X$ oder in $Y$ sind.
			\item Der Schnitt $X \cap Y = \{x \in X : x \in Y\}$, ist die Menge aller Elemente, die sowohl in $X$ als auch in $Y$ sind.
			\item Für $Y \subset X$ schreiben wir $X \setminus Y$ sprich "`$X$ ohne $Y$"' für die Menge $\{x \in X : x \not\in Y\}$
			\item Das "`kartesische Produkt"' $X \times Y$ ist die Menge aller geordneten Tupel $\{(x, y) : x\in X, y\in Y\}$  
		\end{enumerate}
		\textbf{Beispiele:}
		\begin{enumerate}
			\item $\{1, 2, 4\} \cap \{2, 3\} = \{2\}$
			\item $\R \times \R = \R^2$
			\item Die Elemente der Menge $\{1, \{1\}, 2\}$ sind genau $1, \{1\}, 2$ 
		\end{enumerate}
	\end{definition}
	
	\begin{definition}[Abbildungen]
		Seien $X$, $Y$ Mengen. Als Abbildung von $X$ nach $Y$ bezeichnen wir eine Vorschrift $f$, welche jedem Element $x\in X$ genau ein Element $y\in Y$ zuordnet. Wir schreiben
		$$f : X \rightarrow Y,\quad x \mapsto f(x).$$
	\end{definition}
	
	
	\begin{definition}[Gleichheit von Abbildungen]
		Zwei Abbildungen $f : X \rightarrow Y,\ g : X \rightarrow Y$ heißen gleich, wenn für alle $x \in X$ gilt $f(x) = g(x)$.
	\end{definition}

	\begin{definition}[Bild und Urbild]
		Sei $f: X\rightarrow Y, M \subset X, N \subset Y$
		\begin{enumerate}
			\itemsep0cm
			\item Wir schreiben   $f(M) = \{y \in Y : $ es existiert $x \in M$ mit $f(x) = y \} \subset Y$ Bild von $M$
			\item $f^{-1}(N) = \{x \in X : f(x) \in N\} \subset X$ Urbild von $N$
		\end{enumerate}
		\textbf{Beispiele}:\\[.25cm]
		\begin{minipage}[t]{.5\textwidth}
			$X = \{1, 2, 3\}$, $Y = \{3, 4, 5, 6\}$\\ $f(1) = 4, f(2) = 5, f(3) = 5$
			\begin{itemize}
				\itemsep0cm 
				\item $M = \{1, 2\} \subset X$
				\item $f(M) = \{4, 5\} \subset Y$
				\item $f(\emptyset) = \emptyset \subset Y$
				\item $f(X) = \{4, 5\}$
				\item $N = \{3, 4, 5\}$
				\item $f^{-1}(N) = \{1, 2, 3\}$
				\item $f^{-1}(\emptyset) = \emptyset$
				\item $f^{-1}(\{6\}) = \emptyset$
				\item $f^{-1}(\{5\}) = \{2, 3\}$
			\end{itemize}
		\end{minipage}\vspace{.5cm}
		\begin{minipage}[t]{.5\textwidth}
			$X = \R, Y = \R$
			\begin{itemize}
				\item $f : X \rightarrow Y, x \mapsto f(x) =  x^2$
				\item $f([1,2]) = [1, 4] \subset Y$
				\item $f^{-1}(\{0\}) = \{0\}$
				\item $f^{-1}(\{1\}) = \{-1, 1\}$
				\item $f^{-1}(\{-1\}) = \emptyset$
			\end{itemize}
		\end{minipage}
	\noindent
	\textbf{Achtung:} $f^{-1}(N)$ ist nur definiert für Mengen $N \subset Y$. Insbesondere ist $f^{-1}$ (zumindest jetzt) keine Abbildung von $Y$ nach $X$.
	\end{definition}
	
	\begin{definition}[Einschränkung von Funktionen]
		Es sei $f : X \to Y$ eine Abbildung, $M \subset X $. Die Einschränkung von $f$ auf $M$ ist die Abbildung\linebreak $f|_M = M \to Y, x \mapsto f(x)$.
		\begin{bem}
			Der Unterschied zu $f$ ist nur der eingeschränkte Definitionsbereich.\\
			$$f  :\R \to \R,\ x \mapsto f(x) = x^2$$$$
			M = R^+_0 = \{x \in \R : x \ge 0\}$$$$
			(f|_M)^{-1}(\{1\}) = \{1\}
			$$
		\end{bem}
	\end{definition}

	\begin{definition}[Injektivität, Surjektivität, Bijektivität]
		\label{def1.8}
		Es sei $f : X \to Y$ eine Abbildung.
		\begin{enumerate}
			\item $f$ heißt injektiv, falls gilt
			$$\left(x,\ x'\in X, f(x) = f(x')\right) \Rightarrow x = x'$$
			\item $f$ heißt surjektiv, falls gilt
			$$f(X) = Y$$
			\item  $f$ heißt bijektiv, falls $f$ injektiv und surjektiv ist.
			
		\end{enumerate}
		\textbf{Beispiel: } $f : \R \to \R, x \mapsto f(x) = x^2$ ist nicht injektiv, da $f(-1) = f(1), 1 \neq -1$. $f$ ist auch nicht surjektiv, da $f(x) \ge 0$.\ \ $f|_{\R^+_0} : \R^+_0 \to \R$ ist injektiv, aber nicht surjektiv.\ \ 		$f|_{\R^+_0} : \R^+_0 \to \R^+_0$ ist injektiv, und surjektiv, also bijektiv.\\
	\end{definition}
	
	\begin{definition}[Umkehrfunktionen]
		\label{def1.9}
		Es sei $f : X \to Y$ bijektiv. Wir schreiben dann $f^{-1} : Y \to X, f^{-1}(y) = x$ mit dem eindeutig definierten $x \in X$, sodass gilt $f(x) = y$.\\
		\begin{bem}
			Die Sinnhaftigkeit der \hyperref[def1.9]{Definition \ref{def1.9}} folgt sofort aus der \hyperref[def1.8]{Definition von Bijektivität}.
		\end{bem}
	\end{definition}
	
	\begin{satz}
		Sei $X$ eine endliche Menge, so sind für $f : X \to X$ folgende Aussagen äquivalent:
		\begin{enumerate}
			\itemsep0cm
			\item f ist injektiv 
			\item f ist surjektiv
			\item f ist bijektiv
		\end{enumerate}
		\begin{bem}
			Für nicht endliche Mengen haben wir einfache Gegenbeispiele:
			$$f : \N \to \N,\ x \mapsto f(x) = 2x$$
		\end{bem}
		\begin{proof}
			$X$ ist eine endliche Menge, wir schreiben $X = \{x_1, \dots, x_n\}$ mit paarweise verschiedenen $x_j$.
			\begin{enumerate}
				\item[i)] Wir zeigen zunächst $1. \Rightarrow 2.$. Zu zeigen ist also: Falls $f$ injektiv ist, so ist $f$ auch surjektiv. Dies wird impliziert durch die Aussage "`Ist $f$ \textit{nicht} surjektiv, so ist $f$ auch \textit{nicht} injektiv"', welche wir zeigen:\\
				Sei $f$ also nicht surjektiv -- also $f(X) \neq X$. Damit besteht $f(X)$ aus $m < n$ Elementen. Verteilt man aber $n$ Elemente in $m < n$ Schubladen, so muss eine Schublade existieren, in der mehr als ein Element ist. Damit kann $f$ nicht injektiv sein (es existiert $x \neq x'$ mit $f(x') = f(x)$).
				\item[ii)] $2. \Rightarrow 1.$: Sei $f$ also nicht injektiv, dann existieren nach Definition $x, x' \in X, x' \neq x$ aber $f(x) = f(x')$. Damit kann aber $f(X)$ höchstens $n-1$ Elemente enthalten und $f$ ist auch nicht surjektiv.
				\item[iii)] $3. \Rightarrow 1.$: trivial nach der Definition der Bijektivität
				\item[iv)] $3. \Rightarrow 2.$: ebenso
				\item[v)] $1. \Rightarrow 3.$: Aus Injektivität folgt bereits Surjektivität und damit auch Bijektivität.
				\item[vi)] $2. \Rightarrow 3.$: Aus Surjektivität folgt bereits Injektivität und damit auch Bijektivität.
			\end{enumerate}
		\end{proof}
	\end{satz}
	
	\begin{definition}[Komposition von Abbildungen]
		Es seien $X, Y, Z$ Mengen, $f: X \to Y,\ g : Y \to Z$ Abbildungen.
		Dann definiert $g \circ f : X \to Z, x \mapsto g(f(x)) = (g \circ f)(x)$ die Komposition von Abbildungen.
		\begin{bem}
			Es gilt Assoziativität: $(h \circ g) \circ f = h \circ (g \circ f)$ für $f : X \to Y, g : Y \to Z , h : Z \to A$\\
			aber \textit{nicht} Kommutativität, d.h. im Allgemeinen gilt nicht  $f\circ g = g \circ f$ für $f : X \to X, g : X \to X$, denn \\
			$$f : \R \to R, f(x) = x + 1$$$$
			g : \R \to \R, f(x) = x^2$$
			ist ein Gegenbeispiel, denn im Allgemeinen gilt \textit{nicht}, dass $(x + 1)^2 = x^2 + 1$.
		\end{bem}
	\end{definition}
	
	\begin{definition}[Identische Abbildung]
		Mit  $Id_X : X \to X$ bezeichnen wir die identische Abbildung $x \mapsto x$.
	\end{definition}

	\begin{lem}[Identität und Surjektivität bzw. Injektivität]
		Es sei $f : X \to Y$ eine Abbildung, $X,\ Y \neq \emptyset$. Dann gilt:
		\begin{enumerate}
			\itemsep0cm
			\item $f$ ist genau dann injektiv, wenn eine Abbildung $g : Y \to X$ existiert, mit $g \circ f = Id_X$
			\item $f$ ist genau dann surjektiv, wenn $g : Y \to X$ existiert, mit $f \circ g = Id_Y$
			\item $f$ ist genau dann bijektiv, falls $g : Y \to X$ existiert, so dass sowohl $g \circ f = Id_X$ und $f \circ g = Id_Y$. Es gilt dann $g = f^{-1}$
		\end{enumerate}
		\begin{proof}
			\begin{enumerate}
				\item Sei $f$ injektiv. Dann existiert zu jedem $y \in f(X)$ genau ein $x \in X$ mit $f(x) = y$. Wir setzen $g(y) = x$ für ebensolche $y = f(x)$. Nun wählen wir $x_0\in X$ beliebig und setzen $g(y') = x_0$ für alle $y' \in \setminus f(X)$. Dieses $g$ erfüllt die Bedingung.\\
				Sei nun $g : Y \to X$ mit $g \circ f = Id_X$. Seien $x, x' \in X$ mit $f(x) = f(x')$. Es gilt $x = Id_X(x) = (g \circ f)(x) = g(f(x)) = g(f(x')) = (g \circ f)(x') = Id_X(x') = x'$. Also ist $f$ injektiv.
				\item Sei f surjektiv. Zu jedem $y \in Y$ wählen wir ein $x \in X$ mit $f(x) = y$ und setzen $g(y) = x$. Damit gilt $f \circ g = Id_Y$.\\
				Umgekehrt, sei $g : Y \to X$, so dass $f \circ g = Id_Y$. Sei $y \in Y$, dann gilt $y = f(g(y))$. Sei $x' = g(y)$. Damit ist $y = f(x'), x' \in X$ und $y \in f(X)$. Damit ist f surjektiv.
				\item Sei $f$ bijektiv. Die nun definierte Abbildung $f^{-1} : Y \to X$ erfüllt die Voraussetzung an $g$.\\
				Falls aber $g$ existiert mit $g \circ f = Id_x$ und $f \circ g = Id_Y$, dann erfüllt $g$ die Voraussetzungen von 1. und 2. und $f$ ist sowohl injektiv als auch surjektiv. Es gilt dann auch $g = f^{-1}$.
			\end{enumerate}
		\end{proof}
	\end{lem}
	
	\begin{definition}[Menge aller Abbildungen]
		Seien $X$, $Y$ Mengen. Mit $\abb(X, Y)$ bezeichnen wir die Menge aller Abbildungen von $X$ nach $Y$.
		\begin{bem}
			$\{ f \in \abb(X, Y) :\ f \text{ surjektiv}\}$ ist nun ebenfalls definiert.
		\end{bem}
	\end{definition}
	
	\begin{definition}[Mächtigkeit von Mengen]
		Es seien $X$, $Y$ Mengen. Wir sagen $X$ ist gleichmächtig wie $Y$, falls eine bijektive Abbildung von $X$ nach $Y$ existiert.\\
		\begin{bem}
			Für endliche  Mengen $M$ gilt $\#M = m$ genau dann, wenn $M$ gleichmächtig wie $\{1, 2, \dots, m\}$ ist.
		\end{bem}
	\end{definition}
	
	\begin{definition}[Potenzmenge]
		Sei $M$ eine Menge. Die Menge aller Teilmengen von $M$ heißt Potenzmenge von $M$, kurz $2^M$.
		\begin{bem}
			Für eine (beliebige nicht notwendigerweise bijektive) Abbildung $f : X \to Y$ ist $f^{-1}$ eine Abbildung von $2^Y$ nach $2^X$.
		\end{bem}
	\end{definition}
	
	\begin{satz}[Mächtigkeit von $2^M$]
		Sei $M$ eine endliche Menge mit $\#M = m$, $m \in \N \cup \{0\}$. Dann gilt $\#2^M = 2^m$.\\
		\begin{proof}
			Für $m = 0$ gilt $M = \emptyset$ und die Aussage ist klar, denn $2^\emptyset = \{\emptyset\}$, und diese Menge besitzt ein Element.\\
			Rest des Beweises mittel Induktion:\\
			Wir nennen $K \subset \N$ die Menge der natürlichen Zahlen $m$, für welche die Aussage gilt, und zeigen:
			\begin{enumerate}
				\itemsep0cm
				\item $1 \in K$
				\item falls $m \in K$ so ist auch $m + 1 \in K$.
			\end{enumerate}
			Damit folgt (nach dem Induktionsprinzip), dass  K = \mN\ und der Satz ist gezeigt.\\
			\begin{description}[labelindent = 12pt, labelwidth = 1.0cm, leftmargin = 1.0cm]
				\item[Zu 1.:] Die einelementige Menge M schreiben wir als $\{x\}$, die Teilmengen sind $\emptyset, \{x\}$. Somit ist $2^M = \{\emptyset, \{x\}\}$ mit $\#2^M = 2 = 2^1$.
				\item[Zu 2.:] Es sei also $\#M = m + 1$  und $M_m$ eine Menge mit $\# M_m = m$. Wir dürfen annehmen, dass gilt $\#2^{M_m} = 2^m$. Wir schreiben M als $M_m \cup \{x\}, x \not\in M_m$. Wir schreiben\\
				$2^M = \{$Menge aller Teilmengen von $M$, welche $x$ nicht enthalten$\} \cup \{$Menge aller Teilmengen von $M$, welche $x$ enthalten$\} = A \cup B$ und es gilt $\#2^M = \#A + \#B$.\\
				$\#A = \#2^{M_m} = m$, da $A = 2^{M_m}$.\\
				Jede Menge in $B$ ist aber eine Menge in $2^{M_m}$ vereinigt mit $\{x\}$ und $\#B = 2^m$. Somit gilt $\#2^M = 2^m + 2^m = 2^{m + 1}$.\\
				Damit gilt die Aussage für $m + 1$.
			\end{description}
		\end{proof}\\[.25cm]
		Wir kennen bereits das \hyperref[defmengenoperationen]{direkte (bzw. kartesische) Produkt} zweier Mengen $X \times Y = \{(x, y) : x\in X, y \in Y\}$.\\
	\end{satz}

	\begin{definition}[Graph einer Funktion]
		Es sei $f : X \to Y$ eine Abbildung. Die Menge $\Gamma_f = \{(x, f(x)) \in X \times Y\}$ nennen wir Graph von $f$.
	\end{definition}
	
	\begin{definition}[Relationen]
		Noch nützlicher ist das direkte Produkt, um eine sogenannte Relation zu definieren.
		Eine Relation R auf einer Menge X ist eine Teilmenge von $X \times X$.
		Wir sagen für $x, y \in X$, dass $x \sim y$ genau dann, wenn $(x, y) \in R$.\\
		\textbf{Beispiel:}
		\begin{align*}
			x &\sim y \Leftrightarrow x \le y\\
			&\sim\ :=\text{"`Steht in Relation zu"'}
		\end{align*}
		Für das Beispiel gilt dann $R = \{(x, y) \in X \times X : x \le y\}$.
	\end{definition}
	
	\begin{definition}[Äquivalenzrelationen]
		Eine Relation $\sim$ auf $X$ heißt Äquivalenzrelation, falls gilt:
		\begin{enumerate}[leftmargin=3cm, rightmargin=3cm]
			\item $x \sim x$\hfill (Reflexivität)
			\item $x \sim y \Rightarrow y \sim x$\hfill (Symmetrie)
			\item $x \sim y \land y \sim z \Rightarrow x \sim z$\hfill (Transitivität)
		\end{enumerate}
		für alle $x, y, z \in X$.\\
		\textbf{Beispiele:}
		\begin{itemize}
			\item "`$=$"' auf Zahlensystemen
			\item Sei $X = 2^N $. Für $x, y \in X$ gelte $x \sim y$ falls endliche Teilmengen $A$, $B$ von $x$ und $y$ mit $x \setminus A = y \setminus B $ %TODO: check
		\end{itemize}
	\end{definition}
	
	\begin{definition}[Äquivalenzklassen]
		Sei $X$ eine Menge mit Äquivalenzrelation $\sim$. Eine Menge $A \subset X$ heißt Äquivalenzklasse bezüglich $\sim$, falls gilt:
		\begin{enumerate}
			\item $A \neq \emptyset$ 
			\item $x, y \in A \Rightarrow x \sim y$
			\item $x \in A,\ y \in X,\ x \sim y \Rightarrow y \in A$
		\end{enumerate}
	\end{definition}
	
	\begin{prop}[Partitionierung in Äquivalenzklassen]
		\label{prop122}
		Sei $X$ eine Menge mit Äquivalenzrelation $\sim$. Dann gehört jedes $a \in X$ zu genau einer Äquivalenzklasse $A$ bezüglich $\sim$. Für zwei Äquivalenzklassen $A$, $A'$ gilt entweder $A = A'$ oder $A\cap A' = \emptyset$.\\
		\begin{proof}
			Für $a \in X$ definieren wir die Menge $A = \{x \in X : a \sim x\}$.
			Weil $a \sim a$, gilt $a \in A$, somit ist $A \neq \emptyset$. 
			Sind nun $x, y \in A$, so gilt $a \sim x \land a \sim y$. Damit folgt $x \sim a$ und $a \sim y$ und somit $x \sim y$.
			Für $x \in A, y \in X$ mit $x \sim y$. gilt $a \sim x, x \sim y$ also $a \sim y$ und somit $y \in A$.
			Damit ist $A$ eine Äquivalenzklasse und $a$ ist in \textit{mindestens} einer Äquivalenzklasse enthalten.\\[.125cm]
			Es ist noch zu zeigen, dass zwei Äquivalenzklassen entweder gleich oder disjunkt sind.\\
			Seien also $A, A'$ Äquivalenzklassen mit $A \cap A' \neq \emptyset$. Also existiert $b \in A\cap A'$. Falls nun $x \in A$, so gilt $x \sim b$. Nachdem $b$ auch in $A'$ liegt, folgt aber $x \in A'$. Damit folgt $a \subset A'$. Die Umkehrung, also $A' \subset A$, folgt ebenso.
		\end{proof}
	\end{prop}
	
	\vspace{.25cm}
	
	\begin{definition}[Quotientenmenge]
		Es sei X eine Menge mit Äquivalenzrelation $\sim$. Die Menge der Äquivalenzklassen in $X$ bezeichnen wir  als Quotientenmenge und schreiben für diese Menge $X/{\sim}$.\\
		\begin{bem}
			Wir können eine Abbildung definieren, welche jedem $a \in X$ dessen Äquivalenzklasse zuordnet:
			$X \to x/{\sim}, a \mapsto A_a$ (nach \hyperref[prop122]{Proposition \ref{prop122}} eindeutig zugeordnete Äquivalenzklasse).
			Ein solches $a$ heißt dann Repräsentant der Äquivalenzklasse $A_a$.\\
		\end{bem}
		\noindent\textbf{Beispiel: }
		Sei $X = \N$. Wir schreiben $X \sim y$, falls sowohl $x$ als auch $y$ gerade bzw. ungerade Zahlen sind.
		Sei $a \in X$. Die zugehörige Äquivalenzklasse ist gegeben durch:
		\begin{enumerate}[leftmargin=3cm]
			\itemsep0cm
			\item Die Menge aller geraden Zahlen, falls $a$ gerade ist.
			\item Die Menge aller ungeraden Zahlen, falls $a$ ungerade ist.
		\end{enumerate}
	\end{definition}

\section{Gruppen}

	\begin{definition}[Verknüpfungen]
		Es sei $G$ eine Menge. Eine Verknüpfung $\ast$ auf $G$ ist eine Abbildung:
		\begin{alignat*}{3}
			\ast :\ & G \times G &&\to G\\
			&(a, b) &&\mapsto \ast(a, b)
		\end{alignat*}
		\begin{bem}
			Oft schreiben wir einfach $a \ast b$ für $\ast(a, b)$.\\
		\end{bem}
		\noindent\textbf{Beispiele:}
		\begin{enumerate}[leftmargin=2cm]
			\itemsep0cm
			\item $G = \N$, $ \ast(a, b) = a \cdot b$
			\item $G = \N$, $ \ast(a, b) = a + b$
			\item Sei $X$ eine Menge und $G = \abb(X, X)$, dann ist $\ast(f, g) = f \circ g$
		\end{enumerate}		
	\end{definition}
	
	\begin{definition}[Gruppen]
		\label{def125}
		Eine Menge G mit Verknüpfung $\ast$ heißt Gruppe, falls gilt:
		\begin{enumerate}[leftmargin=3cm, rightmargin=1cm]
			\item $(a \ast b) \ast c = a \ast (b \ast c)$ \hfill(Assoziativität)
			\item Es existiert ein Element $e \in G$, sodass gilt:
				\begin{enumerate}
					\item $a \ast e = a$ für alle $a \in G$ \hfill (neutrales Element)
					\item Für alle $a \in G$ existiert $a' \in G$ mit $a' \ast a = e$ \hfill (inverses Element)
				\end{enumerate}
		\end{enumerate}
		Die Gruppe heißt abelsch, falls zusätzlich gilt $$a \ast b = b \ast a\text{ für alle $a, b \in G$}$$\vspace{-.5cm}
		\begin{bem}
			Wir schreiben oft einfach $a \cdot b$ bzw. $ab$ für $a \ast b$.\\
		\end{bem}
		\noindent
		\textbf{Beispiele}
		\begin{enumerate}
			\item $G = \Z$, $\ast(a, b) = a + b$. Dabei ist $e = 0$ und $a' = -a$ 
			\item $G = \Q \setminus\{0\}$, $\ast(a, b) = a \cdot b$. Dabei ist $e = 1$ und $a' = \frac{1}{a}$
			\item $G = \{f \in \abb(X, X), f\text{ bijektiv}\}, \ast(f, g) = f \circ g$. Dabei ist $e = Id_X$ und das Inverse $f^{-1}$
		\end{enumerate}
		\emph{Achtung}: 1 und 2 sind abelsch, 3 nicht notwendigerweise.
	\end{definition}
	
	\begin{prop}[Eindeutigkeit neutrales Element]
		Es sei $G$ eine Gruppe. Dann gilt
		\begin{enumerate}
			\itemsep0cm
			\item Das neutrale Element ist eindeutig bestimmt, und es gilt auch $a \ast e = a$
			\item Das inverse Element $a'$ ist zu jedem $a \in G$ eindeutig bestimmt und es gilt auch $a \ast a' = e$
		\end{enumerate}
		\vspace{.25cm}
		\begin{proof}
			Wir betrachten ein $e \in G$ und ein $a \in G$, wobei $e$ ein neutrales Element ist. Es sei $a'$ ein Inverses zu $a$. Es folgt 
			$a a' = e (a a') = (a'' a') (a a') = a'' (a' (a a')) = a'' ((a' a) a') = a'' (e a') = a'' a' = e$.\\
			Somit gilt $a e = a (a' a) = (a a') a = a$.\\
			Sei $\hat{e}$ ein anderes neutrales Element. Dann gilt $e \hat{e} = e$ und $e \hat{e} = \hat{e}$. Damit folgt $e = \hat{e}$.\\
			Sei nun $\hat{a}'$ ein weiteres inverses Element, dann folgt 
			$\hat{a}' = \hat{a}' e = \hat{a}' (aa') = (\hat{a}'a)a' = ea' = a'$\\
		\end{proof}\vspace{.25cm}
		\begin{bem} $ $
			\begin{enumerate}
				\itemsep0cm
				\item Wir schreiben $a^{-1}$ für das (nun) eindeutig bestimmte inverse Element zu a.
				Es gilt also $a^{-1}a = aa^{-1} = e$ sowie $(a^{-1})^{-1} = a$ und $(ab)^{-1} = b^{-1}a^{-1}$, denn $(b^{-1}a^{-1})(ab) = b^{-1}((a^{-1}a)b) = b^{-1}(eb) = b^{-1}b = e$
				\item Es folgen auch die Kürzungsregeln:
				\begin{enumerate}[leftmargin=3cm]
					\itemsep0cm
					\item $a \hat{x} = ax \Rightarrow x = \hat{x}$
					\item $\hat{y}a = ya \Rightarrow y = \hat{y}$
				\end{enumerate}
			\end{enumerate}
		\end{bem}
	\end{prop}
	
	\begin{definition}[Rechts- und Linkstranslation]
		Für $a \in G$, $G$ eine Gruppe, schreiben wir
		\begin{enumerate}[leftmargin=5cm, rightmargin=4cm]
			\item $\tau_a : G \to G$, $x \mapsto x a$\hfill (Rechtstranslation)
			\item $_{a}\tau : G \to G$, $x \mapsto a x$ \hfill (Linkstranslation)
		\end{enumerate}
	\end{definition}
	
	\begin{lem}$ $\vspace{-.75cm}
		\begin{enumerate}
			\item Falls $G$ eine Gruppe ist, so sind $\tau_a$ und $_{a}\tau$ bijektiv.
			\item Sei $G$ eine Menge mit assoziativer Verknüpfung. Dann folgt \hyperref[def125]{Definition \ref{def125}.2} aus Surjektivität von $\tau_a$ und $_{a}\tau$
		\end{enumerate}
		\vspace{.25cm}
		\begin{proof}
			\begin{enumerate}
				\item Bijektivität folgt aus  $(\tau_a)^{-1}$ gegeben durch $(\tau_a)^{-1}(x) = x a^{-1}$, denn $(\tau_a)^{-1}(\tau_a(y)) = \tau_a(y)a^{-1} = (y a) a^{-1} = y$ für jedes $y \in G$.
				\item Seien also $\tau_a$ und $_{a}\tau$ surjektiv. Dann existiert für jedes $b \in G$ eine Lösung für 
				$x a = b$ sowie $a y = b$. 
				Damit existiert aber zu $a \in G$ ein  $e$ mit $ea = a$. Für beliebiges $b \in G$ folgt dann $e b = e (a y) = (e a) y = ay = b$.	Durch Lösen von $x a = e$ bekommen wir analog das Inverse Element zu $a$.
			\end{enumerate}
		\end{proof}
		\vspace{.25cm}
		\begin{bem}$ $
			\begin{enumerate}
				\item Falls die Gefahr der Verwechslung besteht, schreiben wir gerne $(G, \ast)$ für eine Gruppe $G$ mit Verknüpfung $\ast$, 
					beispielsweise $(\Q, +)$ für \mQ mit Addition, oder $(\Q \setminus \{0\}, \cdot)$ für $\Q \setminus \{0\}$ mit Multiplikation.
				\item Bei der Verknüpfung $+$ gehen wir immer von Kommutativität aus.
				\item Endliche Gruppen kann man mit einer (Gruppen-) Tafel darstellen:
				\begin{center}
					\begin{tabular}{c || c  c  c}
						$\ast$   & $e$      & $\cdots$ & $a_i$	    \\\hline\hline
						$e$      & $e$      & $\cdots$	& $a_i$     \\
						$\vdots$ & $\vdots$ & $\ddots$	& $\vdots$  \\
						$a_j$ 	 &$a_j$     & $\cdots$	& $a_i * a_j$
					\end{tabular}
				\end{center}				
				\item Es gibt nur eine zweielementige Gruppe:
				\begin{center}
						\begin{tabular}{c || c | c}
							$\ast$ & $e$ & $a$\\\hline\hline
							$e$    & $e$ & $a$\\\hline
							$a$    & $a$ & $e$
						\end{tabular}
				\end{center}
			\end{enumerate}
		\end{bem}
	\end{lem}
	
	\begin{definition}[Untergruppen]
		Es sei $(G, \cdot)$ eine Gruppe, $G' \subset G$. $G'$ heißt Untergruppe von G, falls für $a, b \in G'$ auch gilt:\vspace{-.125cm}
		\begin{enumerate}[leftmargin=3cm]
			\itemsep0cm
			\item $ab \in G'$
			\item $a^{-1} \in G'$
		\end{enumerate}
	\end{definition}
	
	\begin{definition}[Homo- und Isomorphismen auf Gruppen]
		Seien $(G, \cdot), (H, *)$ Gruppen, und $\varphi : G \to H$ eine Abbildung.
		\begin{enumerate}
			\item Die Abbildung $\varphi$ heißt Homomorphismus, falls gilt:
				$$\varphi(a \cdot b) = \varphi(a) * \varphi(b)\text{ für alle }a, b \in G$$
			\item $\varphi$ heißt Isomorphismus, falls $\varphi$ zusätzlich bijektiv ist.
		\end{enumerate}
	\end{definition}

	\begin{prop}[Untergruppen sind Gruppen]
		Es sei $(G, \cdot)$ eine Gruppe, $G'$ eine Untergruppe von G. Dann ist $(G', \cdot)$ selbst eine Gruppe.\\
		\begin{proof}
			Assoziativität folgt sofort. Es existiert ein $a^{-1}$ in $G'$, somit auch $e = aa^{-1} \in G'$.\\
		\end{proof}
	\end{prop}
	
	\begin{prop}[Eigenschaften von Homomorphismen]
		Sei $\varphi : G \to H$ ein Homomorphismus von Gruppen $(G, \cdot)$, $(H, \ast)$. Dann gilt
		\begin{enumerate}
			\itemsep0cm
			\item $\varphi(e) = \hat{e}$ mit neutralen Elementen $e \in G, \hat{e} \in H$
			\item $\varphi(a^{-1}) = (\varphi(a))^{-1}$ für alle $a \in G$
			\item Für einen Isomorphismus $\varphi$ ist auch $\varphi^{-1}$ ein Homomorphismus
		\end{enumerate}
		\begin{proof}
			\begin{enumerate}
				\item $\hat{e} * \varphi(e) = \varphi(e) = \varphi(e \cdot e) = \varphi(e) * \varphi(e)$. Nach der Kürzungsregel folgt $\hat{e} = \varphi(e)$
				\item Nach 1. gilt \ $\hat{e} = \varphi(e) = \varphi(a^{-1} a) = \varphi(a^{-1}) * \varphi(a)$ also ist $\varphi(a^{-1}) = (\varphi(a))^{-1}$				
				\item Wir betrachten $c, d \in H$ mit $c = \varphi(a)$, $d = \varphi(b)$. Dann gilt $\varphi(a b) = \varphi(a) * \varphi(b) = c * d$, also $\varphi^{-1}(c * d) = \varphi^{-1}(\varphi(a b)) = ab = \varphi^{-1}(c) \varphi^{-1}(d)$
			\end{enumerate}	
		\end{proof}
		
		\textbf{Beispiele:}
		\begin{enumerate}
			\item $G = (\R, +), H = (\{x \in \R : x > 0\}, \cdot)$
				$$\exp : \R \to \R^+_*, x \mapsto e^x$$
				ist ein Isomorphismus, denn $e^{x + y} = e^x e^y$.
			\item Wir betrachten $(\Z, +)$. Sei $m \in \Z$. Dann ist $\varphi_m : \Z \to \Z, a \mapsto ma$ ein Homomorphismus, denn $m(a + b) = ma + mb$.\ Das Bild $\phi_m(\Z) = m\Z = \{m a : a \in \Z\} \subset \Z$  ist eine Untergruppe von $(\Z, +)$, denn $ma + mb = m(a + b) \in m\Z$ und $-(ma) = m(-a) \in m\Z$.\\	Dazu betrachten wir die Menge $r + m\Z$ (für $r \in \{0, 1, \dots, m-1\}$) mit $r + m\Z = \{r+ma : a \in \Z\}$. Dann gilt $\Z = (0 +m\Z) \cup (1 + m\Z) \cup \dots \cup(m-1 \cup m\Z)$ und die Vereinigung ist disjunkt.\\	Für $a \in \Z$ gilt $\frac{a}{m} = k + \frac{r}{m}$ für $k \in \Z, r \in \{0, \dots, m-1\}$ (Division mit Rest). Dann gilt $ a \in r + m\Z$. (denn $a = km + r$).\\	Wir bezeichnen die Mengen $r + m\Z$ auch als sogenannte "`\textit{Restklassen modulo $m$}"'.\\	Falls $a, a'$ in derselben Klasse $r +m\Z$ sind, gilt $\frac{a-a'}{r} \in \Z$, und wir schreiben $a \equiv a' \mod m$ (ist kongruent zu). Zu $a \in \Z$ schreiben wir $\bar{a} = a + m\Z$, die zu $a$ gehörige Restklasse und wir definieren eine Addition $\bar{a} + \bar{b} = \overline{a + b}$. Wir müssen sicherstellen, dass die Definition nicht von der Auswahl des Repräsentanten abhängt, das ist aber leicht zu sehen.\\ $\bar{a} = \bar{a'}, \bar{b} = \bar{b'}$, dann folgt auch schon, dass gilt $\overline{a + b} = \overline{a' + b'}$.
		\end{enumerate}
	\end{prop}
	
	\begin{satz*}[Zyklische Gruppen]
		Für $m \in \N$  sei $\Z/m\Z = \{\bar{0}, \dots, \overline{m-1}\}$.\\
		Dann gilt, dass $\Z/m\Z, +$ ($+$ definiert wie oben) eine abelsche Gruppe ist.
		Die Abbildung $\Z \to \Z/m\Z, a \mapsto \bar{a} = a + m\Z$ ist ein surjektiver Homomorphismus.\\
		Beweis: Übung.\\
		Wir nennen diese Gruppen die zyklischen Gruppen der Ordnung $m$.
	\end{satz*}

\section{Ringe und Körper}
	
	\begin{definition}[Ringe]
		Es sei $R$ eine Menge, $+ : R \times R \to R$ und $\cdot : R \times R \to R$ Verknüpfungen. $(R, +, \cdot)$ heißt Ring, falls gilt:
		\begin{enumerate}
			\item $(R, +)$ ist eine abelsche Gruppe
			\item Die Multiplikation ist $\cdot$ assoziativ.
			\item Das Distributivgesetz gilt:
			\begin{align*}
				a \cdot (b + c) &= ab + ac\\
				(b + c) \cdot a &= ba + ca
			\end{align*}
		\end{enumerate}
		Ein Ring heißt kommutativ, falls gilt $a \cdot b = b \cdot a$ für alle $a, b \in R$.\\
		Falls ein Element $1 \in R$ existiert mit $1 \cdot a = a \cdot 1 = a$ für alle $a \in R$, dann nennen wir dieses Element Einselement.
		Das neutrale Element der Addition $+$ heißt Nullelement (oder $0$).
	\end{definition}


\subsubsection{Proposition 1.34 Absorption durch Nullelement}
Es gilt $0 \cdot a = a \cdot 0 = 0$.\\
\textbf{Beweis}\\
Wir erinnern uns an die Kürzungsregel: $\al + \xi = \beta + \xi \Rightarrow \al = \beta$.\\
Wir schreiben $0 + 0a = 0a = (0 + 0) a = 0a + 0a \Rightarrow 0 = 0a$\\
Ebenso folgt $0 = a0$.\\
\\
\textbf{Beispiele}
\begin{enumerate}
\item{$(\Z, + \cdot)$, $(\Q, +, \cdot), (\R, + \cdot)$.}
\item{$\Z.m\Z$ mit + wie bisher und $\bar{a} \cdot \bar{b} = \overline{ab}$ (Nach Überprüfung der Unabhängigkeit von der Wahl des Repräsentanten)}
\end{enumerate}
\textbf{Beispiel}\\
Die 2x2-Matrizen $A = \begin{pmatrix}a & b\\c & d\end{pmatrix}$ bilden einen Ring mit\\
$\begin{pmatrix}a & b\\c & d\end{pmatrix} + \begin{pmatrix}e & f\\g & h\end{pmatrix} = \begin{pmatrix}a + e & b + f\\c + g & d + h\end{pmatrix}$\\
$\begin{pmatrix}a & b\\c & d\end{pmatrix} \cdot \begin{pmatrix}e & f\\g & h\end{pmatrix} = \begin{pmatrix}ac+bg & af+bh\\ce+dg & cf+dh\end{pmatrix}$\\
Die gewünschten Eigenschaften folgen sofort. Es gilt aber:\\
$\begin{pmatrix}1 & 1\\0 & 1\end{pmatrix} \begin{pmatrix}1 & 0\\1 &1\end{pmatrix} \neq \begin{pmatrix}1 & 0\\1 & 1\end{pmatrix} \begin{pmatrix}1 & 1\\0 & 1\end{pmatrix}$

\subsubsection{Definition 1.35 Unterring und Ringhomomorphismus}
\begin{enumerate}
\item{
Es sei $(R, +, \cdot)$ ein Ring, $R' \subset R$. $(R', +, \cdot)$ hei\ss{}t Unterring, falls $(R', +)$ eine Untergruppe von $(R, +)$ ist und gilt $a, b \in R' \Rightarrow ab \in R'$
}
\item{
Es seien $(R, +, \cdot)$, $(S, \hat{+}, \hat{\cdot})$ Ringe, $\varphi : R \to S$ eine Abbildung. $\varphi$ hei\ss{}t Ringhomomorphismus, falls gilt $\varphi(a + b) = \varphi(a) \hat{+} \varphi(b)$ und $\varphi(ab) = \varphi(a) \hat{\cdot} \varphi(b)$ für alle $a, b \in R$.
}
\end{enumerate}

\subsubsection{Definition 1.36 Körper}
Es sei K eine Menge, $+ : K \times K \to K, \cdot : K \times K \to K$ Verknüpfungen. $(k, +, \cdot)$ hei\ss{}t Körper, falls gilt:
\begin{enumerate}
\item{$(K, +)$ ist eine abelsche Gruppe}
\item{$K^*$ sei gegeben durch $K \setminus \{0\}$. Dann gilt $(K^*, \cdot)$ ist eine abelsche Gruppe.}
\item{Für $a, b, c \in K$ gilt  $a (b+c) = ab + bc$ und $(b+c) a = ba + ca$}
\end{enumerate}
\textbf{Bemerkung}\\
Das neutrale Element der Multiplikation bezeichnen wir mit Eins $( = 1)$, das Inverse zu a bezüglich der Multiplikation mit $a^{-1}$ oder $\frac{1}{a}$, bezüglich der Addition mit $-a$.

\subsubsection{Proposition 1.37 Rechenregeln für Körper}
Sei $(K, +, \cdot)$ ein Körper. Dann gilt
\begin{enumerate}
\item{$1 \neq 0$}
\item{$0a = a0 = 0$}
\item{$ab = 0 \Rightarrow a = 0 \lor b = 0$}
\item{$a(-b) -(ab)$ und $(-a)(-b) = ab$}
\item{$x a = \hat{x}a$ und $a \neq 0 \Rightarrow x = \hat{x}$}
\end{enumerate}
\textbf{Beweis}
\begin{enumerate}
\item{Folgt sofort, denn $(K^*, \cdot)$ ist eine Gruppe.}
\item{Folgt analog zu Ringen.}
\item{Folgt aus Gruppeneigenschaft von $(K^*, \cdot)$, da $(K^*, \cdot)$ unter der Multiplikation abgeschlossen ist, und somit a oder b nicht in $K^*$ sein kann (also 0 ist)}
\item{Wir rechnen \\
$ab + a(-b) = a (b - b) = a 0 = 0$\\
und\\
$(-a)(-b) = -((-a)b) = -(-(ab)) = ab$}
\item{Die Regel gilt für $x, \hat{x}$ beide in $K^*$. Ist aber $\hat{x} = 0$, so gilt $\hat{x}a = 0$ nach 2. und mit 3. folgt die Aussage.}
\end{enumerate}
\textbf{Beispiele}
\begin{enumerate}
\item{$(\Q, +, \cdot), (\R, +, \cdot)$.}
\item{Die komplexen Zahlen $\C$, wie folgt definiert. Für $(a, b), (c, d) \in \R \times \R$ sei\\
$(a, b)+(c, d) = (a + c, b + d)$ und\\
$(a,b)\cdot (c,d) = (ac-bd, ad + bc)$.\\
Mit $(0, 0)$ als Nullelement und $(1, 0)$ als Einselement.\\
Das additive Inverse zu $(a, b)$ ist dann $(-a, -b)$, das Multiplikative Inverse ist $(\frac{a}{a^2+b^2}, -\frac{b}{a^2 + b^2})$\\
Wir bezeichnen den so konstruierten Körper mit $\C$.\\
Die Abbildung $\R \to \C, a \mapsto (a, 0)$ ist injektiv. Wir sehen, dass zwischen $\R \times \{0\}$ und $\{(a, b) \in \C : b = 0\}$ nicht unterschieden werden muss, denn \\
$
(a, 0) (b, 0) = (ab, 0)\\
(a, 0) + (b, 0) = (a+b, 0)
$\\
Wir schreiben $i = (0, 1) \in \C$ und $(a, b) = (a, 0) + (0, b) = a + ib$.\\
Es gilt $i^2 = ii = -1$. Weiterhin schreiben wir  für $z = (a, b) \in \C, \bar{z} = (a, -b)$. (bzw. $z = a + ib, \bar{z} = a - ib$). (Komplex konjugiertes)\\
Für komplexe Zahlen $\lb, \mu$ gilt dann $\overline{\lb + \mu} = \bar{\lb} + \bar{\mu}$ sowie $\overline{\lb \mu} = \bar{\lb}\bar{\mu}$ und $\lb \in R \Leftrightarrow lb = \bar{\lb}$\\
Für $\lb = a+ib \in \C$ sehen wir $\lb \bar{\lb} = (a + bi) (a - bi) = a^2 + b^2 \in \R$ und wir definieren den Absolutbetrag $|\lb| = \sqrt{\lb \bar{\lb}}$.\\
Damit gilt, dass $d(\lb, \mu) = |\lb - \mu|$ ein Metrik im Sinne von Kap 0 darstellt. (denn $d(\mu, \lb) = d(\lb, \mu),\\
d(\mu, \lb) = 0 \Leftrightarrow \lb = \mu,\\
d(\mu, \lb) + d(\lb, \kappa) \ge d(\mu, \kappa)$)\\
(Das ist die selbe Metrik, die bereits im $\R^2$ eingeführt wurde.)\\
$d(x, y) = \sqrt{(x - y, x - y)} = \sqrt{(x_1-y_1)^2 + (x_2 - y_2)^2}$ mit ($(\xi, \eta) = \xi_1 \eta_1 + \xi_2 \eta_2$).\\
Neu ist die Identität $|\lb \cdot \mu| = |\lb| |\mu|$\\
Wir betrachten noch eine geometrische Anschauung der komplexen Zahlen. Es sei $\lb \in \C$ mit $|\lb| = 1$. Dann gilt, dass $\lb^{-1} = |\frac{1}{\lb}| = 1$  (folgt aus der Formel für das Inverse bezgl. Multiplikation in \mC).\\
In der Analysis lernen wir, dass gilt:\\
- es existiert ein eindeutiges $\al \in [0, 2\pi)$, so dass $\lb = cos(\al) + i \sin(\al) = e^{i\al}$ für $\lb \in \C, |\lb| = 1$.\\
Wir bezeichnen $\al$ als Argument von $\lb$, also $\al = \arg \lb$.\\
Sei nun $\lb \in \C \setminus 0$ beliebig (d.h. ohne die Einschänkung, dass $|\lb| = 1$). Dann schreiben wir $\arg \lb = \arg \frac{\lb}{|\lb|}$, denn $|\frac{\lb}{|\lb|}|$.\\
Damit gilt $\lb = |\lb| e^{i \arg \lb}$ (für jedes $\lb \in \C$).\\
In der komplexen Ebene $\C = \R^2$ gilt dann:\\
\begin{tikzpicture}
\draw[->] (-1, 0) to (6, 0);
\draw[->] (0, -1) to (0, 6);
\node() at (3, 5) {(a + ib)};
\node() at (3, -0.5) {a};
\node() at (-0.5, 5) {b};
\draw[color=red] (0, 0) to (3, 5);
\node[color=red] at (1.5, 3) {d};
\node() at (1.5, 1) {$\alpha$};
\node() at (6, -0.5) {\mR};
\node() at (-0.5, 6) {i\mR};
\draw[] (3, 0) to [bend right=20] (1.5, 2.5);
\end{tikzpicture}\\
mit $d = |\lb|, \al = \arg \lb$.\\
Wir sehen nun, dass gilt $\lb \mu = |\lb| e^{i \arg \lb} \cdot  |\mu| e^{i \arg \mu} = |\lb||\mu| e^{e \arg\lb} e^{i \arg \mu} = |\lb||\mu| e^{i (\arg\lb + \arg \mu)}$.\\
D.h. Beträge werden multipliziert, Argumente addiert bei der Multiplikation in \mC.
}
\end{enumerate}

\subsubsection{Definition 1.38 Nullteilerfreiheit von Ringen}
Ein Ring $(R, +, \cdot)$ hei\ss{}t Nullteilerfrei, falls für $a, b \in R$ gilt $ab = 0 \Rightarrow a = 0 \lor b = 0$.\\
\\
\textbf{Bemerkung}\\
Wir sehen, dass jeder Körper bereits ein nullteilerfreier Ring ist.\\
\textbf{Beispiele}\\
Auf $\Z/m\Z$ ist bereits eine Addition definiert, mit der $\Z/m\Z$ eine Gruppe wird. Mit der Multiplikation\\
$\bar{a} \cdot \bar{b} = \overline{ab}$\\
für $\bar{a}, \bar{b} \in \Z / m\Z$ und Repräsentanten a und b wird $\Z/m\Z$ zu einem Ring\\
Wie für die Addition zeigen wir unabhängigkeit von der Wahl der Repräsentanten.\\
(Assoziativität und Distributivgesetz sind leicht Nachzurechnen.) Der Ring ist kommutativ.

\subsubsection{Satz 1.39 Nullteilerfreiheit des Restklassenrings}
Der Restklassenring $(\Z/m\Z, +, \cdot)$ ist genau dann nullteilerfrei, wenn m eine Primzahl ist.\\
\\
\textbf{Beweis}\\
Falls m nicht prim ist, gilt $m = k \cdot l$ mit $1 < k, l < m$. Damit gilt $\bar{k} \neq \bar{0}, \bar{l} \neq \bar{0}$, aber $\bar{k} \bar{l}= \overline{kl} = \bar{m} = \bar{0}$.\\Umgekehrt: Sei m prim und $\bar{k} \bar{l} = 0$. Dann gilt $k \cdot l= r \cdot m$, für ein $r \in \Z$. Damit gilt aber, dass mindestens einer der Faktoren $k, l$ einen Faktor m enthält. Also ist $\bar{k} = 0$ oder $\bar{l} = 0$.

\subsubsection{Satz 1.40 Ringe dei Körper sind}
Ein nullteilerfreier, kommutativer Ring K mit endlich vielen Elementen und Eins ist ein Körper.\\
\\
\textbf{Beweis}\\
Nach Lemma 1.28 reicht es zu zeigen, dass die Abbildung ${}_{a}\tau : K^* \to K^* : {}_{a}\tau(x) = ax$ für jedes $a \in K^*$ surjektiv ist. $K^*$ ist eine endliche Menge, also folgt surjektivität aus injektivität. Sei also ${}_a\tau(x) = {}_a\tau(y)$, für x, y aus $K^*$. Es folgt $ax = ay$, also $a (x - y) = 0$. Damit gilt aber  (wegen Nullteilerfreiheit und $a \in K^*$, also $a \neq 0$), dass $x - y = 0$, also $x = y$.

\subsubsection{Definition 1.41 Charakteristik eines Ringes}
Es sei R ein Ring mit Einselement 1. Die Charakteristik  von R ist gegeben durch\\
$\chi(R) = \begin{cases}
0 & \text{, falls } n \cdot 1 \neq 0 \forall n \neq 0\\
min(n \in \N \setminus \{0\}) : n \cdot 1 = 0
\end{cases}$\\
Statt $\chi(R)$ wird auch $char(R)$ verwendet.\\
\\
\textbf{Achtung:} Wir haben benutzt, dass $n \cdot a = a + a + \dots + a$ (n-mal) mit $a \in R, n \in \N$

\subsubsection{Lemma 1.42 Charakteristik von Körpern}
Ist K ein Körper, so gilt $\chi(K)$ ist entweder  Null, oder eine Primzahl.\\
\\
\textbf{Beweis}\\
Angenommen, $\chi(K) = m = k \cdot l \neq 0$ mit  $1 < k, l < m$ (also m keine Primzahl). Es folgt  $0 = m \cdot 1 = (k \cdot l) 1 = (k \cdot 1)(l \cdot 1)$. Wegen Nullteilerfreiheit folgt $k \cdot 1 = 0$ oder $l \cdot 1$ = 0, und somit ein Widerspruch.

\subsubsection*{Definition Schiefkörper}
Ein Körper ohne kommutativität in der Multiplikation nennen wir Schiefkörper. (Beispiel: Quaternionen. Siehe Übungsblatt.)

\section{Vektorräume}
Wir kennen bereits  $\R^n = \R \times \R \times \dots \times \R$ mit Operationen $a + b$ für $a,b \in \R^n$ und $\lb \cdot a$ für $a \in \R^n, \lb \in \R$.

\subsection{Definitionen und elementare Eigenschaften}

\subsubsection{Definition 2.1 Vektorraum}
Es sei K ein Körper, $(V, +)$ eine abelsche Gruppe mit einer Abbildung $K \times V \to V$, $(\lb, b) \mapsto \lb v$\\
so dass gilt 
\begin{enumerate}
\item{$\lb (x + y) = (\lb x) + (\lb y)$}
\item{$(\lb + \mu) x = (\lb x) + (\mu x)$}
\item{$\lb (\mu x) = (\lb \mu) x$}
\item{$1 x = x$}
\end{enumerate}
für alle $x, y \in V$, $\lb, \mu \in K$.\\
(Zu beachten ist hierbei, was Addition der Gruppe, was Multiplikation des Körpers und was die speziell definierte Abbildung ist. Dies ergibt sich jedoch eindeutig aus den Typen der Verknüpften Elemente.).\\
Wir nennen die Abbildung $(\lb, v) \mapsto \lb v$ skalare Multiplikation. Die Gruppe $(V, +)$ mit der skalaren Multiplikation  hei\ss{}t dann K-Vektorraum.\\
\\
\textbf{Bemerkung}
\begin{enumerate}
\item{Ist $(R, +, \cdot)$ ein Ring, $(V, +)$ eine abelsche Gruppe mit Abbildung $R \times V \to V, (\lb, v) \mapsto \lb v$ welche die Bedingungen aus Def. 2,1 erfüllt. Dann ist V ein R-Modul (bzw. Links-R-Modul.).\\
Rechts-R-Moduln analog.}
\item{
\begin{itemize}
\item{Elemente in V hei\ss{}en Vektoren, Elemente in K hei\ss{}en Skalare.}
\item{Das Inverse zu $a \in V$ hei\ss{}t -a (das Inverse für Gruppen mit Addition)}
\end{itemize}
}
\item{
Wir schreiben $(\lb x) + (\mu y) = \lb x + \mu y$ (d.h. ''Punkt vor Strich'' für skalare Multiplikation)
}
\item{
	$K = \R$: reelle Vektorräume.\\
	$K = \C$ : komplexe Vektorräume.
}
\end{enumerate}
\textbf{Beispiele}
\begin{enumerate}
\item{\mRn, siehe Kap 0.}
\item{$\C^n, K = \C$ analog.}
\item{Sei K ein beliebiger Körper, dann ist $K^n$ ein Vektorraum, der aus den n-Tupeln von Körperelementen besteht. Addition in $K^n$ eintragweise, Multiplikation für $\lb \in K$ ebenfalls eintragweise.\\
$
\v{v_1\\ \vdots\\ v_n} + \v{w_1\\ \vdots\\ w_n} = \v{v_1 + w_1\\ \vdots \\ v_n + w_n}\\
\lb \v{w_1\\ \vdots\\ w_n} = \v{\lb w_1\\ \vdots \\ \lb w_n}
$\\
$K^0 := \{0\}$ ist der triviale Vektorraum.}
\item{Es sei K ein Körper, X eine Menge, $V = Abb(X, K)$ mit\\
$(f + g)(x) = f(x) + g(x)$ für alle $x \in X, f, g \in V$.\\
Damit wird V zu einer abelschen Gruppe, denn oben ist eine Addition $+(f, g)$ definiert.\\
Wir definieren nun $(\lb f)(x) = \lb (f(x))$ für alle $\lb \in K, f \in V, x \in X$ als Skalarmultiplikation.\\
Damit wird V zu einem Vektorraum.
}
\end{enumerate}

\subsubsection{Proposition 2.2 Eigenschaften von Vektorräumen}
Es sei V eine K-Vektorraum. Dann gilt
\begin{enumerate}
\item{$0 x = 0 \in V$ für alle $x \in V$}
\item{$\lb 0 = 0$ für alle $\lb \in K$}
\item{Falls $\lb \in K, x \in V, \lb x = 0 \in V$, dann gilt $\lb = 0$ oder $x = 0$.}
\item{$(-1) x = -x$ für alle $x \in V$, mit $-1 $}
\end{enumerate}
\textbf{Beweis}
\begin{enumerate}
\item{$0 x = (0 + 0)x = 0x + 0x \Rightarrow 0x = 0$.}
\item{$\lb 0 = \lb(0 + 0) = \lb 0 + \lb 0 \Rightarrow \lb 0 = 0$.}
\item{Zu zeigen ist $\lb \in K^*, x \in V, \lb x = 0$ dann folgt $x = 0$.\\
Es gilt aber $x = 1 x \overset{\lb \neq 0}{=} (\lb ^{-1} \lb) x = \lb^{-1}(\lb x) = \lb^{-1} 0 = 0$}
\item{$x + (-1) x = 1x + (-1) x = (1 - 1)  x = 0 x = 0$}
\end{enumerate}
\textbf{Bemerkung}\\
Es sei $(G. +)$ eine Gruppe, $y \in G$. Falls gilt $y = y + y$, so folgt $y = 0$, denn die Kürzungsregel besagt $a + \hat{x} = a+x \Rightarrow x = \hat{x}$. Mit $x = 0, \hat{x} = y, a = y$. Also $y +y = y + 0 = y \Rightarrow y = 0$.

\subsubsection{Definition 2.3 Untervektorräume}
Es sei K ein Körper, V ein K-Vektorraum. Weiteres sei $W \subset V$. Dann hei\ss{}t W Untervektorraum von V, falls gilt
\begin{enumerate}
\item{$W \neq \emptyset$}
\item{$v, w \in W \Rightarrow v + w \in W$}
\item{$v \in W, \lb \in K \Rightarrow \lb v \in W$}
\end{enumerate}
\textbf{Beispiel}\\
$V = R^2, W = \{v = (v_1, v_2) \in V : v_1 = 0\}$\\
\textbf{Gegenbeispiel}\\
$V = R^2, W = \{v = (v_1, v_2) \in V : v_2 = 1\}$ ist kein Untervektorraum von V.

\subsubsection{Satz 2.4 Untervektorräume sind Vektorräume}
Ein Untervektorraum ist (mit der induzierten Addition und Skalarmultiplikation) ein Vektorraum.\\
\textbf{Beweis}\\
Sei V ein K-Vektorraum, W ein Untervektorraum von V.
\begin{enumerate}
\item{W ist eine Untergruppe von $(V, +)$, denn W ist nicht leer, abgeschlossen bezüglich der Addition. Das neutrale Element $0 \in W$, denn für ein beliebiges $w \in W$ folgt mit 3., dass $0 = 0w \in W$. Zu $v \in W$ gilt weiter $-v = (-1)v \in W$ nach 3..}
\item{Kommutativität und Assoziativität der Untergruppe $(W, +)$ folgt sofort, Distributivgesetze ebenfalls.}
\end{enumerate}
Damit ist W ein Vektorraum.\\
\\
\textbf{Bemerkung} zur Notation:\\
Es sei I eine Menge und für jedes $a \in I$ sei $M_a$ wieder eine Menge. So ein I nennen wir Indexmenge. Nun verallgemeinern wir.Schnittmengen, etc.\\
$\bigcap_{a\in I} M_a = \{x : x \in M_a \text{ für jedes\ } a \in I\}$\\
$\bigcup_{a\in I} M_a = \{x : x \in M_a \text{ für ein\ } a \in I\}$

\subsubsection{Lemma 2.5}
Es sei V ein K-Vektorraum, I eine Indexmenge und für jedes $a \in I$ sei $W_a \subset V$ ein Untervektorraum. Dann gilt
\begin{enumerate}
\item{$W = \bigcap_{a \in I} W_a$ ist ein Untervektorraum von V.}
\item{Seien $a, b \in I$, dann folgt $\hat{W} = W_a \ \cup W_b$ ist ein Untervektorraum von V genau dann, wenn $W_a \subset W_b$ oder $W_b \subset W_a$}
\end{enumerate}
\textbf{Beispiele}\\
$V = R^3, I = \{1, 2\},\\
W_1 = \{v = (v_1, v_2, v_3) \in V : v_1 = 0\},\\
W_2 = \{v = (v_1, v_2, v_3) \in V : v_2 = 0\}\\
W = w_1 \cap W_2 = \{v = (v_1, v_2, v_3) \in V : v_1 = v_2 = 0\}$ ist ein Untervektorraum.\\
$W_1 \cup W_2 = \{v = (v_1, v_2, v_3) \in V : v_1 = 0 \lor v_2 = 0\}$ ist kein Untervektorraum von V, denn $w_1 = (0, 1, 1) \in W_1, w_2 = (1, 0, 1) = W_2$, aber $w_1 + w_2 = (1, 1, 2)$ ist nicht in $W_1 \cup W_2$.\\
\\
\textbf{Beweis}
\begin{enumerate}
\item{Es gilt $0 \in W_a$ für jedes $a \in I$, also gilt $0 \in W$\\
Es seien $x, y \in W$, also gilt $x, y \in W_a$ für jedes $a \in I$. Nachdem $W_a$ (für jedes a) ein Untervektorraum von V ist, gilt $x + y \in W_a$ für jedes $a \in I$, also $x + y \in W$. Ebenso folgt $\lb x \in W$.}
\item{''$\Leftarrow$'' folgt sofort, denn wenn $W_a \subset W_b$, so gilt $W_a \cup W_b = W_b$ und somit $W = W_b$ UVR (Untervektorraum).\\
''$\Rightarrow$'' Sei $\hat{W} = W_a \cup W_b \subset V$ ein UVR und sei $W_a \not\subset W_b$. Zu zeigen ist nun, $W_b \subset W_a$. Es sei $x \in W_b$, wir zeigen, dass folgt $x \in W_a$. Sei $y \in W_a \setminus W_b$ (so ein y existiert, nachdem $W_a \not\subset W_b$). Es folgt $x + y \in \hat{W}$, also $x + y \in W_a$ oder $x + y \in W_b$. Es gilt aber, dass $y = (x + y) - x$, und somit $x + y\not\in W_b$. Somit gilt $x + y \in W_a$, also $(x + y) - y = x \in W_a$.}
\end{enumerate}

\subsubsection{Definition 2.6 Linearkombination und Erzeugendensysteme}
Es sei V ein K-Vektorraum, $E \subset V$ eine Menge.
\begin{enumerate}
\item{Für jedes $e \in E$ sei $\lb_e \in K$, so dass nur endlich viele $\lb_e \neq 0$ sind. Dann schreiben wir $\sum_{e \in E}\lb_e \cdot e = \sum_{e\in E, \lb_e \neq 0} \lb_e \cdot e \in V$ und $\sum_{e \in V} \lb_e \cdot e$ hei\ss{}t Linearkombination der $e \in E$.}
\item{$x \in V$ hei\ss{}t darstellbar als Linearkombination der $e \in E$, falls $\lb_e \in k$ existeiren, mit $\lb_e \neq 0$ für endlich viele $e \in E$ und es gilt $x = \sum_{e \in E}\lb_e \cdot e$.}
\item{$span(E) = \{x \in V : x \text{ als Linearkombination der } e \in E \text{ darstellbar}\}$}
\item{Falls gilt $W = span(E)$, so hei\ss{}t $E \subset V$ Erzeugendensystem von W.}
\item{$W \subset V$ hei\ss{}t endlich erzeugt, über K, falls ein Erzeugendensystem für W mit nur endlich vielen Elementen existiert.}
\end{enumerate}
\textbf{Beispiel}\\
$V = R^2, E = \{(1, 0), (0, 1), (1, 1)\} \subset V$. Dann gilt $V = span(E)$, denn sei $v = (v_1, v_2) \in R^2, v_1, v_2 \in \R$ und es gilt $v = v_1 + \cdot (1, 0) + v_2 \cdot (0, 1)$. V ist also endlich erzeugt.

\subsubsection{Lemma 2.7}

Es sei V ein k-Vektorraum, $E \subset V$. Dann gilt
\begin{enumerate}
\item{$span(E)$ ist ein UVR von V.}
\item{Falls $W \subset V$ ein UVR ist mit $E \subset W$, so gilt $span(E) \subset W$. (Es folgt ,dass $span(E) \subset V$ der minimale Untervektorraum ist, der E enthält.)}
\end{enumerate}
\textbf{Beweis}
\begin{enumerate}
\item{Folgt sofort aus der Definition, denn 
\begin{enumerate}
\item{$span(E) \neq \emptyset$, denn $0 \in span(E)$}
\item{Für $v_1, v_2 \in span(E)$ gilt $v_1 + v_2 \in span(E)$, denn wir können die Koeffizienten $\lb_e^{v1}$ und $\lb_e^{v2}$ addieren. Ebenso für $\mu v_1$.}
\end{enumerate}}
\item{Sei $W \subset V$ ein Untervektorraum, $E \subset W$. Es folgt sofort, dass (wegen Abgeschlossenheit von W bezüglich der Addition und Skalarmultiplikation), dass jede Linearkombination der $e \in E$ wieder in W liegt.}
\end{enumerate}
\end{document}
